{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qb1Lts5hbfSB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrqOlSbFmD6z"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RkvvizrmKAD"
   },
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def options(options):\n",
    "  old_opts = tf.config.optimizer.get_experimental_options()\n",
    "  tf.config.optimizer.set_experimental_options(options)\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    tf.config.optimizer.set_experimental_options(old_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "j8q9WBBucWli",
    "outputId": "d406c529-8f13-478e-94d4-500179743305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHavvMzxctTM"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBayj8HAitrR"
   },
   "source": [
    "### Regular training using model.fit function and MNIST Digits dataset - Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "HiUmyc8IcqJv",
    "outputId": "b99e0737-0c93-48d0-a835-de19242a07a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdCE-jOScL2w"
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "def timeit(func):\n",
    "    def timed():\n",
    "        start = time.time()\n",
    "        func()\n",
    "        print(f'Took: {(time.time() - start):.5f}')\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "s0vSIIbidtu-",
    "outputId": "f026ac27-b0fc-409e-b665-336c779e399c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.3727 - accuracy: 0.8968 - val_loss: 0.2024 - val_accuracy: 0.9424\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.1576 - accuracy: 0.9557 - val_loss: 0.1168 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.1062 - accuracy: 0.9702 - val_loss: 0.0911 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 0.0833 - accuracy: 0.9760 - val_loss: 0.0746 - val_accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0707 - accuracy: 0.9799 - val_loss: 0.0716 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.0663 - val_accuracy: 0.9786\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.0664 - val_accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.0644 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0472 - accuracy: 0.9862 - val_loss: 0.0649 - val_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0609 - val_accuracy: 0.9805\n",
      "Took: 103.15932\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timeit(fit_model)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DutJPxyidzYZ"
   },
   "outputs": [],
   "source": [
    "model.save('1_base_digits_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHQ71-S_i12x"
   },
   "source": [
    "### Model Trainig with Custom training with TF.Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhZf88NqjhwC"
   },
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkeBHMNImyZN"
   },
   "outputs": [],
   "source": [
    "# Prepare the validation dataset.\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "St5VnajfnYqo"
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVixagbvnUxZ"
   },
   "outputs": [],
   "source": [
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-rJhT5enWw3"
   },
   "outputs": [],
   "source": [
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "DKUY1QuioQyf",
    "outputId": "115682c9-caae-41c2-9a11-f1a848fe23ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIXxmJNLobr1"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model_2(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model_2.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model_2.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4bVeKiIojXN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model_2(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yETQHRSWotDm",
    "outputId": "a2d7d195-8181-44ed-d9f1-388cb888dd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "WARNING:tensorflow:Layer reshape_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Training loss (for one batch) at step 0: 2.3726\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.2476\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.4041\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.2822\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.1462\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9064\n",
      "Validation acc: 0.9564\n",
      "Time taken: 9.71s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.2526\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1872\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1468\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0852\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.1585\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9641\n",
      "Validation acc: 0.9694\n",
      "Time taken: 8.87s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.1724\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.1849\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.0554\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0775\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0736\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9738\n",
      "Validation acc: 0.9752\n",
      "Time taken: 8.92s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.1718\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0498\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1122\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0379\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0445\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9786\n",
      "Validation acc: 0.9773\n",
      "Time taken: 8.95s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.1330\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0193\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.0837\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0711\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0488\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9815\n",
      "Validation acc: 0.9795\n",
      "Time taken: 8.91s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.0318\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0152\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1354\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0440\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.2256\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9834\n",
      "Validation acc: 0.9794\n",
      "Time taken: 9.98s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.0242\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0340\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1189\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0126\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0312\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9852\n",
      "Validation acc: 0.9791\n",
      "Time taken: 8.83s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.0443\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0460\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.0311\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0369\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.1663\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9860\n",
      "Validation acc: 0.9790\n",
      "Time taken: 8.87s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.0522\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0327\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1720\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0180\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0269\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9871\n",
      "Validation acc: 0.9801\n",
      "Time taken: 8.84s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.0315\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: 0.0331\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: 0.1402\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: 0.0797\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: 0.0248\n",
      "Seen so far: 51264 samples\n",
      "Training acc over epoch: 0.9883\n",
      "Validation acc: 0.9803\n",
      "Time taken: 8.80s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOi1LbtCowlL"
   },
   "outputs": [],
   "source": [
    "model_2.save('2_custom_model_with_TFfunction_Grappler_digits_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYQtO6AKLgpi"
   },
   "source": [
    "### Convert The above .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist.h5) into TFLite (3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svuqCc75qDAS"
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqq2sr8aLeUd"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TGo952DrMW3J",
    "outputId": "d211aa87-f7f1-41fa-a4c5-8810699efc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5','3_custom_model_with_TFfunction_Grappler_digits_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdCX2D-zOfO7"
   },
   "source": [
    "### Evaluate and find the model load and unit inference time for above .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "zN7YPV8Rxrai",
    "outputId": "d768f15e-d85c-4c0c-8f29-4d15ab64300b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "\n",
      " Test accuracy on full test set: 0.9803\n",
      "{'Time to only unit infer': 0.02315521240234375}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "score = model.evaluate(test_images, test_labels, verbose =0)\n",
    "print('\\n', 'Test accuracy on full test set:', score[1])\n",
    "\n",
    "data = test_images[0]\n",
    "data = data.reshape((1, 28, 28))\n",
    "data_y = train_labels[0:1]\n",
    "# unit inference \n",
    "start_time_infer = time.time()\n",
    "score = model.evaluate(data, data_y, verbose=0)\n",
    "results1 = {'Time to only unit infer': (time.time() - start_time_infer) }\n",
    "print (results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NPM6owXFHAY8",
    "outputId": "47d4b6d3-304e-4d82-b3b4-f28360b09830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "{'Time to load model and then unit infer': 0.977961540222168}\n"
     ]
    }
   ],
   "source": [
    "start_load_time_infer = time.time()\n",
    "model_dummy_load = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5', custom_objects=None, compile = True)\n",
    "score = model.evaluate(test_images, test_labels, verbose =0)\n",
    "results2 = {'Time to load model and then unit infer': (time.time() - start_load_time_infer) }\n",
    "print (results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdCX2D-zOfO7"
   },
   "source": [
    "### Evaluate and find the model load and unit inference time of the .tflite version (3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite) of the .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmEzZRq_OhNL"
   },
   "outputs": [],
   "source": [
    "# Evaluation function for tflite models\n",
    "def evaluate_model(interpreter):\n",
    "  \n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in test_images:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == test_labels[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  results = {'Test accuracy on full test set:': accuracy}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4idSsHK2SD0K",
    "outputId": "867c29bf-e8bc-461a-b410-b5efd5406ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load 3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite and infer': 0.006373167037963867}\n",
      "{'Time to only infer': 0.0002899169921875}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test accuracy on full test set:': 0.9803}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('tflite_models/3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Time to only infer': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load 3_custom_model_with_TFfunction_Grappler_digits_mnist.tflite and infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb561cTxUuBO"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist.h5) to int-only quantized tflite model (4_custom_train_grappler_Integer_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "jI1d_9rVU9MB",
    "outputId": "89bcaa37-b0df-476d-fdff-332a479ddd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then integer quantized model to: 4_custom_train_grappler_Integer_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_int_quant_model = converter.convert()\n",
    "tflite_model_integeronly_file = '4_custom_train_grappler_Integer_model.tflite'\n",
    "\n",
    "with open(tflite_model_integeronly_file, 'wb') as f:\n",
    "  f.write(tflite_int_quant_model)\n",
    "\n",
    "print('Saved custom trained grappler then integer quantized model to:', tflite_model_integeronly_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0015883445739746094}\n",
      "{'Time to only infer': 0.0004112720489501953}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test accuracy on full test set:': 0.9807}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating custom_train_grappler_Integer_model.tflite\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./4_custom_train_grappler_Integer_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Time to only infer': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koOpXJTIfBCn"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist.h5) to Int with float fallback quantized tflite model (5_custom_train_grappler_Int_float_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NJBtdmpbfHG4",
    "outputId": "6ac0657c-e114-49d4-96f6-e194d5894580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then int with float quantized model to: 5_custom_train_grappler_Int_float_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_int_float_quant = converter.convert()\n",
    "tflite_model_int_float_quant_file = '5_custom_train_grappler_Int_float_model.tflite'\n",
    "\n",
    "with open(tflite_model_int_float_quant_file, 'wb') as f:\n",
    "  f.write(tflite_model_int_float_quant)\n",
    "\n",
    "print('Saved custom trained grappler then int with float quantized model to:', tflite_model_int_float_quant_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0018682479858398438}\n",
      "{'Time to only infer': 0.00042319297790527344}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test accuracy on full test set:': 0.9805}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate custom_train_grappler_Int_float_model.tflite\n",
    "\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./5_custom_train_grappler_Int_float_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Time to only infer': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7IScmoUlpwn"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_digits_mnist) to Float16 tflite model (6_custom_trained_grappler_float16_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "7XD1rO91lwBB",
    "outputId": "65320e0e-c54b-4890-a4b3-2f7d02eeffae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then float16 quantized model to: 6_custom_trained_grappler_float16_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_digits_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = '6_custom_trained_grappler_float16_model.tflite'\n",
    "\n",
    "with open(tflite_model_fp16_file, 'wb') as f:\n",
    "  f.write(tflite_fp16_model)\n",
    "\n",
    "print('Saved custom trained grappler then float16 quantized model to:', tflite_model_fp16_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0012423992156982422}\n",
      "{'Time to only infer': 0.0003726482391357422}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Test accuracy on full test set:': 0.9803}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating custom_trained_grappler_float16_model.tflite\n",
    "\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./6_custom_trained_grappler_float16_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Time to only infer': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Custom-model-training with tf.function.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
