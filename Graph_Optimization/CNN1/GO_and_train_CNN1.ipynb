{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qb1Lts5hbfSB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SrqOlSbFmD6z"
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RkvvizrmKAD"
   },
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def options(options):\n",
    "  old_opts = tf.config.optimizer.get_experimental_options()\n",
    "  tf.config.optimizer.set_experimental_options(options)\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    tf.config.optimizer.set_experimental_options(old_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "j8q9WBBucWli",
    "outputId": "d406c529-8f13-478e-94d4-500179743305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHavvMzxctTM"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBayj8HAitrR"
   },
   "source": [
    "### Regular training using model.fit function and MNIST Fashion dataset - Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "HiUmyc8IcqJv",
    "outputId": "b99e0737-0c93-48d0-a835-de19242a07a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdCE-jOScL2w"
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              batch_size=64,\n",
    "              epochs=10,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "def timeit(func):\n",
    "    def timed():\n",
    "        start = time.time()\n",
    "        func()\n",
    "        print(f'Took: {(time.time() - start):.5f}')\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "s0vSIIbidtu-",
    "outputId": "f026ac27-b0fc-409e-b665-336c779e399c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.5354 - accuracy: 0.8164 - val_loss: 0.4179 - val_accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.3799 - accuracy: 0.8679 - val_loss: 0.3760 - val_accuracy: 0.8710\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.3459 - accuracy: 0.8794 - val_loss: 0.3502 - val_accuracy: 0.8798\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.3246 - accuracy: 0.8872 - val_loss: 0.3396 - val_accuracy: 0.8837\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 12s 199us/sample - loss: 0.3086 - accuracy: 0.8916 - val_loss: 0.3282 - val_accuracy: 0.8844\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.2949 - accuracy: 0.8963 - val_loss: 0.3202 - val_accuracy: 0.8862\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 0.2835 - accuracy: 0.9003 - val_loss: 0.3106 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.2741 - accuracy: 0.9039 - val_loss: 0.3028 - val_accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 186us/sample - loss: 0.2653 - accuracy: 0.9076 - val_loss: 0.2982 - val_accuracy: 0.8941\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.2572 - accuracy: 0.9097 - val_loss: 0.2960 - val_accuracy: 0.8935\n",
      "Took: 112.74551\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timeit(fit_model)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DutJPxyidzYZ"
   },
   "outputs": [],
   "source": [
    "model.save('1_base_fashion_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHQ71-S_i12x"
   },
   "source": [
    "### Model Trainig with Custom training with TF.Function - Graph Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qhZf88NqjhwC"
   },
   "outputs": [],
   "source": [
    "# Prepare the training dataset.\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkeBHMNImyZN"
   },
   "outputs": [],
   "source": [
    "# Prepare the validation dataset.\n",
    "# Reserve 10,000 samples for validation.\n",
    "x_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "St5VnajfnYqo"
   },
   "outputs": [],
   "source": [
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVixagbvnUxZ"
   },
   "outputs": [],
   "source": [
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-rJhT5enWw3"
   },
   "outputs": [],
   "source": [
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "DKUY1QuioQyf",
    "outputId": "115682c9-caae-41c2-9a11-f1a848fe23ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIXxmJNLobr1"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model_2(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model_2.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model_2.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4bVeKiIojXN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model_2(x, training=False)\n",
    "    val_acc_metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yETQHRSWotDm",
    "outputId": "a2d7d195-8181-44ed-d9f1-388cb888dd39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4b7d3130fb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Iterate over the batches of the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Log every 200 batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_step' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOi1LbtCowlL"
   },
   "outputs": [],
   "source": [
    "model_2.save('2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AYQtO6AKLgpi"
   },
   "source": [
    "### Convert The above .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5) into TFLite (3_custom_model_with_TFfunction_Grappler_fashion_mnist.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svuqCc75qDAS"
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqq2sr8aLeUd"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TGo952DrMW3J",
    "outputId": "d211aa87-f7f1-41fa-a4c5-8810699efc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/3_custom_model_with_TFfunction_Grappler_fashion_mnist.tflite'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5','3_custom_model_with_TFfunction_Grappler_fashion_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdCX2D-zOfO7"
   },
   "source": [
    "### Evaluate and find the model load and unit inference time for above .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "zN7YPV8Rxrai",
    "outputId": "d768f15e-d85c-4c0c-8f29-4d15ab64300b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "\n",
      " Test accuracy on full test set: 0.8959\n",
      "{'Time to load model and infer for testset': 1.2047083377838135}\n",
      "{'Unit infer time': 0.024936676025390625}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "start_time_test_set = time.time()\n",
    "\n",
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "score = model.evaluate(test_images, test_labels, verbose =0)\n",
    "print('\\n', 'Test accuracy on full test set:', score[1])\n",
    "results1 = {'Time to load model and infer for testset': (time.time() - start_time_test_set) }\n",
    "\n",
    "data = test_images[0]\n",
    "data = data.reshape((1, 28, 28))\n",
    "data_y = train_labels[0:1]\n",
    "# unit inference \n",
    "start_time_infer = time.time()\n",
    "score = model.evaluate(data, data_y, verbose=0)\n",
    "results2 = {'Unit infer time': (time.time() - start_time_infer) }\n",
    "\n",
    "print (results1)\n",
    "print (results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdCX2D-zOfO7"
   },
   "source": [
    "### Evaluate and find time the model load and unit inference time of the .tflite version (3_custom_model_with_TFfunction_Grappler_fashion_mnist.tflite) of the .h5 Grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmEzZRq_OhNL"
   },
   "outputs": [],
   "source": [
    "# Evaluation function for tflite models\n",
    "def evaluate_model(interpreter):\n",
    "  start_time = time.time()\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in test_images:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == test_labels[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "  results = {'time': (time.time() - start_time),\n",
    "             'accuracy': accuracy}\n",
    "\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4idSsHK2SD0K",
    "outputId": "867c29bf-e8bc-461a-b410-b5efd5406ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0010547637939453125}\n",
      "{'Unit infer time': 0.00041604042053222656}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 1.3081109523773193, 'accuracy': 0.8959}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('tflite_models/3_custom_model_with_TFfunction_Grappler_fashion_mnist.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Unit infer time': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb561cTxUuBO"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5) to int-only quantized tflite model (4_custom_train_grappler_Integer_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "jI1d_9rVU9MB",
    "outputId": "89bcaa37-b0df-476d-fdff-332a479ddd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then integer quantized model to: 4_custom_train_grappler_Integer_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_int_quant_model = converter.convert()\n",
    "tflite_model_integeronly_file = '4_custom_train_grappler_Integer_model.tflite'\n",
    "\n",
    "with open(tflite_model_integeronly_file, 'wb') as f:\n",
    "  f.write(tflite_int_quant_model)\n",
    "\n",
    "print('Saved custom trained grappler then integer quantized model to:', tflite_model_integeronly_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and unit infer': 0.0010979175567626953}\n",
      "{'Unit infer time': 0.00033473968505859375}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 1.6632821559906006, 'accuracy': 0.897}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating custom_train_grappler_Integer_model.tflite\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./tflite_models/4_custom_train_grappler_Integer_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Unit infer time': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and unit infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koOpXJTIfBCn"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5) to Int with float fallback quantized tflite model (5_custom_train_grappler_Int_float_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "NJBtdmpbfHG4",
    "outputId": "6ac0657c-e114-49d4-96f6-e194d5894580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then int with float quantized model to: 5_custom_train_grappler_Int_float_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_int_float_quant = converter.convert()\n",
    "tflite_model_int_float_quant_file = '5_custom_train_grappler_Int_float_model.tflite'\n",
    "\n",
    "with open(tflite_model_int_float_quant_file, 'wb') as f:\n",
    "  f.write(tflite_model_int_float_quant)\n",
    "\n",
    "print('Saved custom trained grappler then int with float quantized model to:', tflite_model_int_float_quant_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0008296966552734375}\n",
      "{'Time to only infer': 0.00027060508728027344}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 1.1398780345916748, 'accuracy': 0.8959}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate custom_train_grappler_Int_float_model.tflite\n",
    "\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./5_custom_train_grappler_Int_float_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Unit infer time': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and unit infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7IScmoUlpwn"
   },
   "source": [
    "### Convert the custom trained grappler model (2_custom_model_with_TFfunction_Grappler_fashion_mnist) to Float16 tflite model (6_custom_trained_grappler_float16_model.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "7XD1rO91lwBB",
    "outputId": "65320e0e-c54b-4890-a4b3-2f7d02eeffae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Saved custom trained grappler then float16 quantized model to: 6_custom_trained_grappler_float16_model.tflite\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./2_custom_model_with_TFfunction_Grappler_fashion_mnist.h5', compile = True)\n",
    "model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = '6_custom_trained_grappler_float16_model.tflite'\n",
    "\n",
    "with open(tflite_model_fp16_file, 'wb') as f:\n",
    "  f.write(tflite_fp16_model)\n",
    "\n",
    "print('Saved custom trained grappler then float16 quantized model to:', tflite_model_fp16_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to load model and infer': 0.0012693405151367188}\n",
      "{'Time to only infer': 0.0003323554992675781}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time': 1.1033220291137695, 'accuracy': 0.8959}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating custom_trained_grappler_float16_model.tflite\n",
    "\n",
    "\n",
    "start_time_qaware_full = time.time()\n",
    "interpreter_custom_tflite_model = tf.lite.Interpreter('./6_custom_trained_grappler_float16_model.tflite')\n",
    "interpreter_custom_tflite_model.allocate_tensors()\n",
    "test_image = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "input_index = interpreter_custom_tflite_model.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_custom_tflite_model.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter_custom_tflite_model.set_tensor(input_index, test_image)\n",
    "start_time_qaware_infer = time.time()\n",
    "interpreter_custom_tflite_model.invoke()\n",
    "results1 = {'Unit infer time': (time.time() - start_time_qaware_infer) }\n",
    "predictions = interpreter_custom_tflite_model.get_tensor(output_index)\n",
    "\n",
    "results = {'Time to load model and unit infer': (time.time() - start_time_qaware_full)}\n",
    "print (results)\n",
    "print (results1)\n",
    "evaluate_model(interpreter_custom_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Custom-model-training with tf.function.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
