{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTyaborA9Uvt"
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aa7Yuka-9CE2"
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y2MkpT2q_fjG"
   },
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgplOk-H9UQA"
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "YApCbSvg9aCF",
    "outputId": "78151c99-049e-4c7f-bd34-9b96b701a811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"Train Image shape:\", train_images.shape, \"Test Image shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dWIJf6Yb9efY"
   },
   "outputs": [],
   "source": [
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kEBTOXUy9g1z"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUeFrj__9lZl"
   },
   "source": [
    "### Regular CNN1 with Conv2D Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "WLFZfq8G9kAx",
    "outputId": "8b00e7bd-8232-4ebb-fbc4-68ebe7dc2f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmQNfOPpH2tJ"
   },
   "source": [
    "### CNN1 with separable filters - Operation optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "4qEQ0-aCH_OR",
    "outputId": "149b1024-31f7-473b-9847-70a0f2c7e350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 26, 26, 12)        33        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,323\n",
      "Trainable params: 20,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sep_model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.SeparableConv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "sep_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2u655iY9vSc"
   },
   "source": [
    "### Train the regular CNN1 with Conv2D: Train Model using MNIST Fashion dataset - Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YuWfvXBk9sWA"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ErTbPia-9yTy",
    "outputId": "9fc93764-6a51-415c-a9c6-f6a4c43b98aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.5313 - accuracy: 0.8206 - val_loss: 0.4137 - val_accuracy: 0.8561\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.3687 - accuracy: 0.8733 - val_loss: 0.3691 - val_accuracy: 0.8721\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.3351 - accuracy: 0.8834 - val_loss: 0.3513 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 0.3148 - accuracy: 0.8903 - val_loss: 0.3322 - val_accuracy: 0.8836\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.2994 - accuracy: 0.8960 - val_loss: 0.3285 - val_accuracy: 0.8834\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.2876 - accuracy: 0.8988 - val_loss: 0.3171 - val_accuracy: 0.8873\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 0.2791 - accuracy: 0.9012 - val_loss: 0.3141 - val_accuracy: 0.8867\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.2684 - accuracy: 0.9057 - val_loss: 0.3054 - val_accuracy: 0.8910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 180us/sample - loss: 0.2597 - accuracy: 0.9093 - val_loss: 0.3046 - val_accuracy: 0.8909\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2538 - accuracy: 0.9099 - val_loss: 0.2967 - val_accuracy: 0.8943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f42de01e240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IAzOk7uW91HL"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save('1_base_fashion_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "ak3QjOXk_Rkq",
    "outputId": "8285a4cc-a0cc-4efa-a756-11ffb196d329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.8943\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXbI4eadJGxD"
   },
   "source": [
    "### Train the Sperable CNN1 using MNIST Fashion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Lx42J_a4JK1B"
   },
   "outputs": [],
   "source": [
    "sep_model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JhK_WQJjJP-5",
    "outputId": "047033aa-20b1-45e7-8ad6-fd1d6529c601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 295us/sample - loss: 0.5647 - accuracy: 0.7995 - val_loss: 0.4707 - val_accuracy: 0.8293\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 17s 285us/sample - loss: 0.4152 - accuracy: 0.8516 - val_loss: 0.4256 - val_accuracy: 0.8474\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.3928 - accuracy: 0.8610 - val_loss: 0.4065 - val_accuracy: 0.8565\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.3809 - accuracy: 0.8645 - val_loss: 0.4024 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.3705 - accuracy: 0.8684 - val_loss: 0.3874 - val_accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.3648 - accuracy: 0.8702 - val_loss: 0.3905 - val_accuracy: 0.8651\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.3593 - accuracy: 0.8723 - val_loss: 0.4018 - val_accuracy: 0.8532\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 290us/sample - loss: 0.3551 - accuracy: 0.8739 - val_loss: 0.3862 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 0.3514 - accuracy: 0.8745 - val_loss: 0.3871 - val_accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 17s 289us/sample - loss: 0.3491 - accuracy: 0.8759 - val_loss: 0.3925 - val_accuracy: 0.8578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4290fa16a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_model.fit(train_images,\n",
    "         train_labels,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "f-_-hbB7JTwb"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "sep_model.save('2_fashion_mnist_model_sperable.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and find the model load and unit inference time for above .h5 seperable model (2_fashion_mnist_model_sperable.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "_IPwNQstJW0y",
    "outputId": "3474c111-573e-4e33-a62e-db3a3ec9702a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = sep_model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "data = test_images[0]\n",
    "data = data.reshape((1, 28, 28))\n",
    "def orig_model_infer_time():\n",
    "  start_time_full = time.time()\n",
    "  model = tf.keras.models.load_model('./2_fashion_mnist_model_sperable.h5', custom_objects=None, compile=True)\n",
    "  start_time_infer = time.time()\n",
    "  model.predict(data)\n",
    "  results = {'Time to load model and then infer': (time.time() - start_time_full),\n",
    "             'Time to only infer': (time.time() - start_time_infer)}\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_model_infer_time_testset():\n",
    "  start_time_testset = time.time()\n",
    "  model = tf.keras.models.load_model('./2_fashion_mnist_model_sperable.h5', custom_objects=None, compile=True)\n",
    "  score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "  results1 = { 'Time to load model and infer for full test set': (time.time() - start_time_testset)}\n",
    "  \n",
    "  return results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to load model and then infer': 0.26890087127685547,\n",
       " 'Time to only infer': 0.0513150691986084}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model_infer_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to load model and infer for full test set': 1.7964997291564941}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model_infer_time_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert The above .h5 seperable model (2_fashion_mnist_model_sperable.h5) into TFLite (3_fashion_mnist_model_sperable_tflite.tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xqq2sr8aLeUd"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TGo952DrMW3J",
    "outputId": "680272ab-3a6b-4362-d911-48991f5e5d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/3_fashion_mnist_model_sperable_tflite.tflite'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_fashion_mnist_model_sperable.h5','3_fashion_mnist_model_sperable_tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Huz4-iVTRVha"
   },
   "source": [
    "### Convert The above .h5 seperable model (2_fashion_mnist_model_sperable.h5) into Integer with Float fall back Quantized model (4_fashion_mnist_seperable_Integer_float_model.tflite) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pdXzgl08RUwa"
   },
   "outputs": [],
   "source": [
    "def Quant_int_with_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_quant_file = tflite_models_dir/filename\n",
    "    tflite_model_quant_file.write_bytes(tflite_model_quant)\n",
    "\n",
    "    return f'Converted - path {tflite_model_quant_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mtybg0WcSTqD",
    "outputId": "449455cd-72a5-49d5-bd12-eed40f945b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/4_fashion_mnist_seperable_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./2_fashion_mnist_model_sperable.h5', '4_fashion_mnist_seperable_Integer_float_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhQiKZ0tTjUM"
   },
   "source": [
    "### Convert The above .h5 seperable model (2_fashion_mnist_model_sperable.h5) into Float 16 Quantized model (5_fashion_mnist_seperable_float16_model.tflite)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yQD8PpVuTiuj"
   },
   "outputs": [],
   "source": [
    "def Quant_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "    tflite_fp16_model = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_fp16_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_fp16_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_fp16_file = tflite_models_fp16_dir/filename\n",
    "    tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_fp16_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2T_StcfxD9IJ",
    "outputId": "b6c01b5a-50bd-4e33-dbc2-f7976290cafd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/5_fashion_mnist_seperable_float16_model.tflite'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./2_fashion_mnist_model_sperable.h5', '5_fashion_mnist_seperable_float16_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOStg9X6MVeT"
   },
   "source": [
    "### Convert The above .h5 seperable model (2_fashion_mnist_model_sperable.h5) into Integer only Quantized model (6_fashion_mnist_seperable_integeronly_model.tflite)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gLIJ9GE5M4wg"
   },
   "outputs": [],
   "source": [
    "def Quant_integer(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    mnist_train, _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "    def representative_data_gen():\n",
    "      for input_value in mnist_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "    tflite_int_quant_model = converter.convert()\n",
    "\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "    tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_integeronly_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CzqUk2GFNobJ",
    "outputId": "ba8c0f49-36b4-4d79-9e35-c5d813ab4dcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/6_fashion_mnist_seperable_integeronly_model.tflite'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./2_fashion_mnist_model_sperable.h5', '6_fashion_mnist_seperable_integeronly_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "HTlL9oRZQcdy"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "tmEzZRq_OhNL",
    "outputId": "5cf1f550-3eb6-49a4-d14b-bfe9731005c0"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_model(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in test_images:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == test_labels[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  results = {'time': (time.time() - start_time),\n",
    "             'accuracy': accuracy}\n",
    "\n",
    "  # Loading Test Image\n",
    "  test_img = np.expand_dims(test_images[0], axis=0).astype(np.float32)\n",
    "\n",
    "  interpreter.set_tensor(input_index, test_img)\n",
    "  start_time_infer = time.time()\n",
    "  interpreter.invoke()\n",
    "\n",
    "  predictions = interpreter.get_tensor(output_index)\n",
    "\n",
    "  result = {\"Unit inference time \" : (time.time() - start_time_infer),\n",
    "            \"Time to load model and infer for testset \": (time.time() - start_time)}\n",
    "  \n",
    "  return result, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LefuJJQOQaxp",
    "outputId": "bc48c81d-235c-46f6-c713-d15fffb9deb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unit inference time:': 6.461143493652344e-05,\n",
       "  'Time to load model and infer for testset: ': 0.7214105129241943},\n",
       " {'time': 0.7213327884674072, 'accuracy': 0.8578})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/3_fashion_mnist_model_sperable_tflite.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LefuJJQOQaxp",
    "outputId": "bc48c81d-235c-46f6-c713-d15fffb9deb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unit inference time:': 0.0001232624053955078,\n",
       "  'Time to load model and infer for testset: ': 0.7637655735015869},\n",
       " {'time': 0.7635705471038818, 'accuracy': 0.8594})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/4_fashion_mnist_seperable_Integer_float_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LefuJJQOQaxp",
    "outputId": "bc48c81d-235c-46f6-c713-d15fffb9deb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unit inference time:': 6.151199340820312e-05,\n",
       "  'Time to load model and infer for testset: ': 0.7136926651000977},\n",
       " {'time': 0.713618278503418, 'accuracy': 0.8578})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/5_fashion_mnist_seperable_float16_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LefuJJQOQaxp",
    "outputId": "bc48c81d-235c-46f6-c713-d15fffb9deb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unit inference time:': 0.0001125335693359375,\n",
       "  'Time to load model and infer for testset: ': 1.227842092514038},\n",
       " {'time': 1.2277169227600098, 'accuracy': 0.862})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = 'tflite_models/6_fashion_mnist_seperable_integeronly_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_model(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wgplOk-H9UQA",
    "oUeFrj__9lZl",
    "s2u655iY9vSc",
    "e5iW0Z_s_zzt",
    "PPNTSd2yASgC",
    "CNKzdQdJAn9A",
    "7_m2WJ8kBJF4",
    "2_7Vs4vCCNlN",
    "CadvCseDBsr8",
    "e4zE--ZSFGXY",
    "EaT2lW_2FVwa",
    "7yK_dxzBCObb",
    "D8Iv3s1tEphP",
    "8HsO71gEIDqy"
   ],
   "name": "CNN_1_FashionMnist_V5",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
