{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4zYZ-j7PRnU"
   },
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQN9b45WPH4a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAzeh1CBPcBL"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvAMKMkOPZv9",
    "outputId": "cd47c730-a1d1-4e7d-d657-f61810a08449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFb6jWAkPfdD"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBUVyLcAPjwi"
   },
   "source": [
    "### Conv2D Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2A-wIeHPgPK",
    "outputId": "17543787-88d8-45cd-ca36-a4038b29b1dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGUrrQKVQKIU"
   },
   "source": [
    "### Train Conv2D Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_d3N_5_PuKE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wR0ljGKmQJA6",
    "outputId": "a02ffc14-9299-4c48-ad45-1e0ff796912f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.3453 - accuracy: 0.9048 - val_loss: 0.1715 - val_accuracy: 0.9488\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.1398 - accuracy: 0.9607 - val_loss: 0.1073 - val_accuracy: 0.9706\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0990 - accuracy: 0.9721 - val_loss: 0.0855 - val_accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.9775 - val_loss: 0.0738 - val_accuracy: 0.9765\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0694 - accuracy: 0.9802 - val_loss: 0.0672 - val_accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0620 - accuracy: 0.9823 - val_loss: 0.0659 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0563 - accuracy: 0.9837 - val_loss: 0.0645 - val_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0510 - accuracy: 0.9850 - val_loss: 0.0588 - val_accuracy: 0.9810\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0577 - val_accuracy: 0.9810\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0634 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f762030c780>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVJXIMgUQRuT"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save('1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fN577u1YQSRT",
    "outputId": "dcdb075a-44a6-4620-e50a-c119bed4d381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVr9KwBiSSNz"
   },
   "source": [
    "### Train model with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jme0bFPQSWUZ",
    "outputId": "04656fd7-aa37-46ee-c6b1-6cb535dcc733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |██                              | 10kB 22.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 20kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 30kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 40kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 51kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 61kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 71kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 81kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 92kB 9.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 102kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 112kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 122kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 133kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 143kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 153kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 163kB 9.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 174kB 9.0MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYgEbllrSYWh",
    "outputId": "6995c63b-dea1-494c-db57-71c688b55ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:220: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXAAYOz0V4ao",
    "outputId": "533e43c5-85d8-4b46-e5e8-39cbe1713b0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICZiOIDKV6vn",
    "outputId": "97913ff9-e660-4a5b-a4ba-dee27db5195c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiKemkTiWFfR",
    "outputId": "76c12249-feb3-4d18-d57a-c8365187fd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfJH9qxzWJov"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWOEo7EiSmbx",
    "outputId": "1d1bd3c2-365b-4068-8a3e-a5c654b08524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  1/422 [..............................] - ETA: 0s - loss: 0.1870 - accuracy: 0.9297WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0083s vs `on_train_batch_end` time: 0.0304s). Check your callbacks.\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9834 - val_loss: 0.0407 - val_accuracy: 0.9880\n",
      "Epoch 2/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 0.0400 - val_accuracy: 0.9885\n",
      "Epoch 3/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 0.0415 - val_accuracy: 0.9883\n",
      "Epoch 4/40\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0438 - val_accuracy: 0.9880\n",
      "Epoch 5/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 0.0447 - val_accuracy: 0.9868\n",
      "Epoch 6/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
      "Epoch 7/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 0.0454 - val_accuracy: 0.9862\n",
      "Epoch 8/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.0467 - val_accuracy: 0.9867\n",
      "Epoch 9/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9892 - val_loss: 0.0470 - val_accuracy: 0.9862\n",
      "Epoch 10/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.0526 - val_accuracy: 0.9847\n",
      "Epoch 11/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.0486 - val_accuracy: 0.9858\n",
      "Epoch 12/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9884 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 13/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9881 - val_loss: 0.0521 - val_accuracy: 0.9852\n",
      "Epoch 14/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0540 - val_accuracy: 0.9848\n",
      "Epoch 15/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0529 - val_accuracy: 0.9845\n",
      "Epoch 16/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.0527 - val_accuracy: 0.9833\n",
      "Epoch 17/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.0552 - val_accuracy: 0.9842\n",
      "Epoch 18/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0557 - val_accuracy: 0.9848\n",
      "Epoch 19/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.0586 - val_accuracy: 0.9845\n",
      "Epoch 20/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0405 - accuracy: 0.9880 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
      "Epoch 21/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0576 - val_accuracy: 0.9832\n",
      "Epoch 22/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0401 - accuracy: 0.9880 - val_loss: 0.0566 - val_accuracy: 0.9843\n",
      "Epoch 23/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 24/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0590 - val_accuracy: 0.9832\n",
      "Epoch 25/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9877 - val_loss: 0.0602 - val_accuracy: 0.9833\n",
      "Epoch 26/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.0580 - val_accuracy: 0.9845\n",
      "Epoch 27/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0572 - val_accuracy: 0.9845\n",
      "Epoch 28/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.0713 - val_accuracy: 0.9782\n",
      "Epoch 29/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 0.0606 - val_accuracy: 0.9828\n",
      "Epoch 30/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.0585 - val_accuracy: 0.9832\n",
      "Epoch 31/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0595 - val_accuracy: 0.9833\n",
      "Epoch 32/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0395 - accuracy: 0.9878 - val_loss: 0.0572 - val_accuracy: 0.9843\n",
      "Epoch 33/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.0598 - val_accuracy: 0.9832\n",
      "Epoch 34/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.0593 - val_accuracy: 0.9838\n",
      "Epoch 35/40\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.0574 - val_accuracy: 0.9847\n",
      "Epoch 36/40\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.0581 - val_accuracy: 0.9837\n",
      "Epoch 37/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.0590 - val_accuracy: 0.9833\n",
      "Epoch 38/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0359 - accuracy: 0.9892 - val_loss: 0.0589 - val_accuracy: 0.9835\n",
      "Epoch 39/40\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0599 - val_accuracy: 0.9827\n",
      "Epoch 40/40\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.0588 - val_accuracy: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f759b5edfd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='log'),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZdROjFMSzqB",
    "outputId": "c9998eb3-fb24-4c00-c67a-f8b44532d3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned test accuracy: 0.9898499846458435\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   X_train, y_train, verbose=0)\n",
    "\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAslc8BbUWrt"
   },
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "tf.keras.models.save_model(model_for_export, '2_mnist_model_pruning.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU74G4M6Uheo"
   },
   "source": [
    "### Q-aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMue-1quUduS",
    "outputId": "b71b08aa-3abc-41a7-eb30-2fe3c7947cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 28, 28)            3         \n",
      "_________________________________________________________________\n",
      "quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,448\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HdBr8QpUn0b",
    "outputId": "2b84c98a-559c-42cb-af69-d66e4deb1f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9822 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.0529 - val_accuracy: 0.9900\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.0539 - val_accuracy: 0.9800\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9989 - val_loss: 0.0559 - val_accuracy: 0.9900\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9800\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9800\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9800\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9700\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9800\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9700\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9800\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9800\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9800\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9700\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9800\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5926e-04 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9800\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9266e-04 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9800\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4518e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9800\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8015e-04 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9800\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0068e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9800\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8319e-04 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9800\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0607e-04 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9700\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6430e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9800\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3454e-04 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9800\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1103e-04 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9800\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6700e-04 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9800\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3171e-04 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9800\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0562e-04 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9800\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7796e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9800\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6342e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3751e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9800\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2988e-04 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9800\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0464e-04 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9800\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8716e-04 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9800\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6894e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6138e-04 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9800\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4883e-04 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9800\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3433e-04 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2307e-04 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9800\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1415e-04 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9778e-04 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9177e-04 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.8276e-04 - accuracy: 1.0000 - val_loss: 0.1662 - val_accuracy: 0.9800\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6531e-04 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6554e-04 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9800\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5173e-04 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 0.9800\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5277e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3939e-04 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9800\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3369e-04 - accuracy: 1.0000 - val_loss: 0.1776 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f759a3d6fd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model against baseline\n",
    "\n",
    "train_images_subset = X_train[0:1000] # out of 60000\n",
    "train_labels_subset = y_train[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                  batch_size=10, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i5mfpIfUttE",
    "outputId": "4bffb5e3-6446-4b49-ccc0-c28a7537410b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.9678999781608582\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = q_aware_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRx896DaUzSZ"
   },
   "outputs": [],
   "source": [
    "q_aware_model.save('3_mnist_model_qaware.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMDgXKixV24s"
   },
   "source": [
    "### Convert Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIW3P66SU5Wh"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "mNpVzGNkV-hT",
    "outputId": "9e031af3-fa1d-45db-8728-9b3de368187b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpz_075670/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted to TFLite, path tflite_models/mnist_model.tflite'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./1_mnist_model.h5','4_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "nP0nqyQnWQmY",
    "outputId": "e98d2c0c-1bc1-44bc-c242-6d07683b198f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1pf3fcld/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp1pf3fcld/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted to TFLite, path tflite_models/mnist_pruning_model.tflite'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_mnist_model_pruning.h5','5_mnist_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI5dR2_BWW0K",
    "outputId": "6e54b8a0-0f64-43f1-db9d-2f029600e846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdel1wugi/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdel1wugi/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quvantaised aware TFLite model to: mnist_model_qaware.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "quantized_aware_tflite_file = '6_mnist_model_qaware.tflite'\n",
    "\n",
    "with open(quantized_aware_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "\n",
    "print('Saved quvantaised aware TFLite model to:', quantized_aware_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QduOdpLHXB7M"
   },
   "source": [
    "### Integer with Float fallback quantaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCaunXAmW0Sa"
   },
   "outputs": [],
   "source": [
    "def Quant_int_with_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "    def representative_data_gen():\n",
    "      for input_value in mnist_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    tflite_model_quant = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_quant_file = tflite_models_dir/filename\n",
    "    tflite_model_quant_file.write_bytes(tflite_model_quant)\n",
    "\n",
    "    return f'Converted - path {tflite_model_quant_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "AgYJEJIcXIA4",
    "outputId": "1ddfb469-2656-47d3-a789-a7b63f274b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl45ce9pe/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpl45ce9pe/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./1_mnist_model.h5', '7_mnist_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "3yLopRzNXLsO",
    "outputId": "ee98dd7b-0c1d-4114-dc97-5e163f01c132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpc7asdszt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpc7asdszt/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_pruning_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./2_mnist_model_pruning.h5','8_mnist_pruning_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BubY_Gfvi9r7",
    "outputId": "cc6502ff-b5b0-4ba2-da7a-15ff360dbdf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6y9831wf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp6y9831wf/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25040"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "quantized_tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_quant_file = tflite_models_dir/\"9_mnist_Qaware_Integer_float_model.tflite\"\n",
    "tflite_model_quant_file.write_bytes(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-dl7BDpX2q8"
   },
   "source": [
    "### Float 16 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1rd9zwoXyI5"
   },
   "outputs": [],
   "source": [
    "def Quant_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "    tflite_fp16_model = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_fp16_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_fp16_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_fp16_file = tflite_models_fp16_dir/filename\n",
    "    tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_fp16_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "bKwgApR-X8uz",
    "outputId": "3e1f8c04-6f63-41d5-bdc8-6e0f79195a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp66upb64f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp66upb64f/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_float16_model.tflite'"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./1_mnist_model.h5', '10_mnist_float16_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "xbwNw7r6X-5U",
    "outputId": "8847cfc7-2b96-4a22-8d8e-1b156edd249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdkb5x_7g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdkb5x_7g/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_float_pruning_model.tflite'"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./2_mnist_model_pruning.h5', '11_mnist_float_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "ID7LoDiqYDz3",
    "outputId": "046a9591-be61-4f43-f06f-2487db6e791f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbep8gvt2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbep8gvt2/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_sperable_float_model.tflite'"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./mnist_model_sperable.h5','mnist_sperable_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGCANtJKmloH",
    "outputId": "b4ee3cd9-4bb8-4e86-a1ba-c0de997b734e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwr5239n4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwr5239n4/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50880"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = tflite_models_dir/\"12_mnist_Qaware_float16_model.tflite\"\n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH-KGhE4YTLk"
   },
   "source": [
    "### Integer Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWQ9VPHuYVQD"
   },
   "outputs": [],
   "source": [
    "def Quant_integer(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "    def representative_data_gen():\n",
    "      for input_value in mnist_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "    tflite_int_quant_model = converter.convert()\n",
    "\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "    tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_integeronly_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "hu2k7mh8YZMg",
    "outputId": "0af8d068-fa20-4ce8-9276-633f67447eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9xmepe7r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9xmepe7r/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/fashion_mnist_integeronly_model.tflite'"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./1_mnist_model.h5', '13_fashion_mnist_integeronly_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "KHd4CHwvYcZM",
    "outputId": "cc381e12-de8f-47f4-b80f-c0110e966154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw7iut9hy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpw7iut9hy/assets\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Converted - path tflite_models/mnist_Integeronly_pruning_model.tflite'"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./2_mnist_model_pruning.h5', '14_mnist_Integeronly_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quant_integer('3_mnist_model_qaware.h5','15_mnist_qaware_integer_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "gRp_DxPEZFnQ",
    "outputId": "f09cf12b-0ff6-4d2a-88df-e868f7276d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy49q8vs1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpy49q8vs1/assets\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f4bf752305f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m  \u001b[0;31m# or tf.uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtflite_int_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.tflite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     return super(TFLiteKerasModelConverterV2,\n\u001b[0;32m--> 831\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    636\u001b[0m         self.inference_input_type, self.inference_output_type)\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcalibrate_and_quantize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calibrate_quantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_sparsify_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[0;34m(self, result, inference_input_type, inference_output_type, activations_type, allow_float)\u001b[0m\n\u001b[1;32m    450\u001b[0m       return calibrate_quantize.calibrate_and_quantize(\n\u001b[1;32m    451\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_input_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m           inference_output_type, allow_float, activations_type)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_is_unknown_shapes_allowed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36mcalibrate_and_quantize\u001b[0;34m(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         np.dtype(activations_type.as_numpy_dtype()).num)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   def calibrate_and_quantize_single(self,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Quantization not yet supported for op: "
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "tflite_int_quant_model = converter.convert()\n",
    "\n",
    "filename = filename+'.tflite'\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLfnYBi_Y_UE"
   },
   "source": [
    "### Evalvate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FlVsfYmfapme"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaROCUPyH0VN"
   },
   "source": [
    "### Keras model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HelUev2D_rQ"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_single_unit(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  data = X_test[0]\n",
    "  data = data.reshape((1, 28, 28))\n",
    "  data_y = y_test[0:1]\n",
    "  score = model.evaluate(data, data_y, verbose=0)\n",
    "\n",
    "  result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UphrjYx4GShd",
    "outputId": "c45fc599-d5a5-4712-dc28-a0199570b9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Score': 1.0, 'Time to single unit infer': 0.2571237087249756}"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4wu0T0JHABA",
    "outputId": "de6d1cdb-e2c7-4842-a2b7-72516a24f3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Score': 1.0, 'Time to single unit infer': 0.21321558952331543}"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./2_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIMCeFsfHUIw"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_test_set(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  score = score = model.evaluate(X_test, y_test, verbose =0)\n",
    "\n",
    "  result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rSz-PSTHiev",
    "outputId": "9c385dd4-4071-454b-d041-80822830571f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_test_function.<locals>.test_function at 0x7f759bd7d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_test_function.<locals>.test_function at 0x7f759bd7d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Score': 0.9787999987602234, 'Time to single unit infer': 0.6961848735809326}"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwFkmrd-HmpA",
    "outputId": "ac6e65a4-42d8-4e7d-9639-c9571179f5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Score': 0.9769999980926514, 'Time to single unit infer': 0.6563079357147217}"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./2_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E973b0qH91Z"
   },
   "source": [
    "### TF Lite Model Evaluvation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ze6PZOG8amGr"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_test_set(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in X_test:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == y_test[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  results = {'time': (time.time() - start_time),\n",
    "             'accuracy': accuracy}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-U4VKkOUSBi"
   },
   "source": [
    "### TF Lite Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkrgvhyOJQTa",
    "outputId": "e882fb6d-c05b-47ac-fcb3-bfe4fbd075ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9788, 'time': 1.447981595993042}"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/4_mnist_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GuvDc23JSbl",
    "outputId": "ec2b42e9-c0f5-4398-eefc-93f8ca7afb12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.977, 'time': 1.4401161670684814}"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/5_mnist_pruning_model.tflite'\n",
    "interpreter_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzVEe8J0kzP2"
   },
   "outputs": [],
   "source": [
    "# Qaware Model\n",
    "tflite_model_file = '6_mnist_model_qaware.tflite'\n",
    "interpreter_qaware = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqqScJyCUYeN"
   },
   "source": [
    "### Integer Float TF Lite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaALN_B-UREA",
    "outputId": "d39a99c4-4dd6-4fcd-88ed-d2e93930192e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9786, 'time': 4.391948699951172}"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/7_mnist_Integer_float_model.tflite'\n",
    "interpreter_int_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNoTU5hKUev5",
    "outputId": "89c23c6c-d105-4cf5-b632-0e140fa717bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9762, 'time': 4.4521284103393555}"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/8_mnist_pruning_Integer_float_model.tflite'\n",
    "interpreter_int_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-aware TF Lite \n",
    "tflite_qaware_model_file = 'tflite_models/9_mnist_Qaware_Integer_float_model.tflite'\n",
    "interpreter_tflite_qaware = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-WBEicYlRYC"
   },
   "source": [
    "### Float Tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB1ptyTEXMY_",
    "outputId": "848b0d91-5d96-4d6e-f9cf-31def9da60c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9788, 'time': 1.4013164043426514}"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/10_mnist_float16_model.tflite'\n",
    "interpreter_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9U5CaiiXOLx",
    "outputId": "91d48c55-7596-40ee-aa3e-c48e082cc8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.977, 'time': 1.406904697418213}"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/11_mnist_float_pruning_model.tflite'\n",
    "interpreter_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_qaware_model_file = 'tflite_models/12_mnist_Qaware_float16_model.tflite'\n",
    "interpreter_tflite_qaware = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okkuq4qBlUtg"
   },
   "source": [
    "### Integer Only TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSSOaD5xYusE"
   },
   "outputs": [],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/13_mnist_integeronly_model.tflite'\n",
    "interpreter_int = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhfqVJESYvXV"
   },
   "outputs": [],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/14_mnist_Integeronly_pruning_model.tflite'\n",
    "interpreter_int_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw6jufPWUi4-"
   },
   "source": [
    "### Single unit Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISNOWEKoMk_T"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_single_unit(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  test_image = np.expand_dims(X_test[0], axis=0).astype(np.float32)\n",
    "  interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "  # Run inference.\n",
    "  interpreter.invoke()\n",
    "\n",
    "  # Post-processing: remove batch dimension and find the digit with highest\n",
    "  # probability.\n",
    "  output = interpreter.tensor(output_index)\n",
    "\n",
    "  results = {'time': (time.time() - start_time)}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CtdfccSNNjTJ",
    "outputId": "c4785d45-2031-4626-af3c-e4e8e515e3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0023622512817382812}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "evaluate_tflite_model_single_unit(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xaD5wuZ-NpS7",
    "outputId": "afbc484d-5d9b-4c19-f2e8-46730bdb24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0004756450653076172}"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RCfwkechNx6D",
    "outputId": "95c1bcbe-acf7-41bf-8593-542e41c9206b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0010595321655273438}"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hE2TT1Asl-T_",
    "outputId": "ffb77f4e-6f83-4b3b-937e-49b65b99007c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0007975101470947266}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "W9B3FA1TV3yK",
    "outputId": "ce64a1e6-6ea2-448d-c1bc-10a97a92171e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0010995864868164062}"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kmyMu1L-X_rJ",
    "outputId": "7dafaf58-7f2e-422f-a78b-ae1e6933fcc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0007212162017822266}"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dTm4xyvVYFRs",
    "outputId": "f3637e39-0eab-42a4-c031-cd3be04596f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0026826858520507812}"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kLjCD9luZyZh",
    "outputId": "9406986d-14af-49d0-f8ba-d17553b17985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0009720325469970703}"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HpG8cjckZ2oS",
    "outputId": "690c6081-f0f8-4ad2-adf0-4ee58dcc6c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0005164146423339844}"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float_pruning)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ezWjyFaJRSZj",
    "6yN3fanmRk8j",
    "jVr9KwBiSSNz",
    "hU74G4M6Uheo",
    "IMDgXKixV24s",
    "QduOdpLHXB7M",
    "P-dl7BDpX2q8",
    "oH-KGhE4YTLk",
    "rLfnYBi_Y_UE",
    "EGG619d3N5Am"
   ],
   "name": "CNN_2_Mnist_V1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
