{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4zYZ-j7PRnU"
   },
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TQN9b45WPH4a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAzeh1CBPcBL"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvAMKMkOPZv9",
    "outputId": "cd47c730-a1d1-4e7d-d657-f61810a08449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tFb6jWAkPfdD"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBUVyLcAPjwi"
   },
   "source": [
    "### Conv2D Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2A-wIeHPgPK",
    "outputId": "17543787-88d8-45cd-ca36-a4038b29b1dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGUrrQKVQKIU"
   },
   "source": [
    "### Train Conv2D Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2_d3N_5_PuKE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wR0ljGKmQJA6",
    "outputId": "a02ffc14-9299-4c48-ad45-1e0ff796912f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 0.3466 - accuracy: 0.9055 - val_loss: 0.1605 - val_accuracy: 0.9533\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.1360 - accuracy: 0.9612 - val_loss: 0.1109 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0963 - accuracy: 0.9721 - val_loss: 0.0848 - val_accuracy: 0.9746\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0787 - accuracy: 0.9773 - val_loss: 0.0729 - val_accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0678 - accuracy: 0.9804 - val_loss: 0.0685 - val_accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0602 - accuracy: 0.9826 - val_loss: 0.0649 - val_accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 167us/sample - loss: 0.0548 - accuracy: 0.9838 - val_loss: 0.0636 - val_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 0.0493 - accuracy: 0.9858 - val_loss: 0.0605 - val_accuracy: 0.9810\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.0464 - accuracy: 0.9863 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.0591 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73fd99e128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wVJXIMgUQRuT"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save('1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fN577u1YQSRT",
    "outputId": "dcdb075a-44a6-4620-e50a-c119bed4d381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVr9KwBiSSNz"
   },
   "source": [
    "### Train model with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jme0bFPQSWUZ",
    "outputId": "04656fd7-aa37-46ee-c6b1-6cb535dcc733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/home/db/.virtualenvs/LR/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYgEbllrSYWh",
    "outputId": "6995c63b-dea1-494c-db57-71c688b55ff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/db/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:219: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXAAYOz0V4ao",
    "outputId": "533e43c5-85d8-4b46-e5e8-39cbe1713b0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICZiOIDKV6vn",
    "outputId": "97913ff9-e660-4a5b-a4ba-dee27db5195c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiKemkTiWFfR",
    "outputId": "76c12249-feb3-4d18-d57a-c8365187fd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wfJH9qxzWJov"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWOEo7EiSmbx",
    "outputId": "1d1bd3c2-365b-4068-8a3e-a5c654b08524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 9s 168us/sample - loss: 0.0490 - accuracy: 0.9860 - val_loss: 0.0377 - val_accuracy: 0.9893\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 8s 151us/sample - loss: 0.0422 - accuracy: 0.9881 - val_loss: 0.0382 - val_accuracy: 0.9902\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 8s 154us/sample - loss: 0.0403 - accuracy: 0.9891 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0398 - accuracy: 0.9888 - val_loss: 0.0406 - val_accuracy: 0.9888\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0395 - accuracy: 0.9889 - val_loss: 0.0449 - val_accuracy: 0.9867\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0385 - accuracy: 0.9887 - val_loss: 0.0420 - val_accuracy: 0.9885\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 8s 152us/sample - loss: 0.0376 - accuracy: 0.9898 - val_loss: 0.0414 - val_accuracy: 0.9888\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.0441 - val_accuracy: 0.9875\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.0466 - val_accuracy: 0.9880\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.0374 - accuracy: 0.9886 - val_loss: 0.0460 - val_accuracy: 0.9868\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.0469 - val_accuracy: 0.9870\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.0482 - val_accuracy: 0.9852\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 9s 157us/sample - loss: 0.0394 - accuracy: 0.9881 - val_loss: 0.0497 - val_accuracy: 0.9840\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.0410 - accuracy: 0.9879 - val_loss: 0.0507 - val_accuracy: 0.9847\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.0401 - accuracy: 0.9885 - val_loss: 0.0511 - val_accuracy: 0.9848\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.0522 - val_accuracy: 0.9838\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.0401 - accuracy: 0.9882 - val_loss: 0.0528 - val_accuracy: 0.9837\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0515 - val_accuracy: 0.9852\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0371 - accuracy: 0.9890 - val_loss: 0.0508 - val_accuracy: 0.9843\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0381 - accuracy: 0.9884 - val_loss: 0.0534 - val_accuracy: 0.9848\n",
      "Epoch 22/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0534 - val_accuracy: 0.9850\n",
      "Epoch 23/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.0619 - val_accuracy: 0.9822\n",
      "Epoch 24/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0401 - accuracy: 0.9881 - val_loss: 0.0562 - val_accuracy: 0.9845\n",
      "Epoch 25/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0588 - val_accuracy: 0.9828\n",
      "Epoch 26/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0377 - accuracy: 0.9888 - val_loss: 0.0582 - val_accuracy: 0.9828\n",
      "Epoch 27/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0365 - accuracy: 0.9894 - val_loss: 0.0568 - val_accuracy: 0.9832\n",
      "Epoch 28/40\n",
      "54000/54000 [==============================] - 9s 162us/sample - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.0685 - val_accuracy: 0.9800\n",
      "Epoch 29/40\n",
      "54000/54000 [==============================] - 9s 163us/sample - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0593 - val_accuracy: 0.9827\n",
      "Epoch 30/40\n",
      "54000/54000 [==============================] - 9s 164us/sample - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.0613 - val_accuracy: 0.9813\n",
      "Epoch 31/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0360 - accuracy: 0.9899 - val_loss: 0.0608 - val_accuracy: 0.9822\n",
      "Epoch 32/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.0600 - val_accuracy: 0.9823\n",
      "Epoch 33/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0343 - accuracy: 0.9901 - val_loss: 0.0598 - val_accuracy: 0.9825\n",
      "Epoch 34/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.0620 - val_accuracy: 0.9817\n",
      "Epoch 35/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.0609 - val_accuracy: 0.9823\n",
      "Epoch 36/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0614 - val_accuracy: 0.9817\n",
      "Epoch 37/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0630 - val_accuracy: 0.9813\n",
      "Epoch 38/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.0314 - accuracy: 0.9911 - val_loss: 0.0635 - val_accuracy: 0.9815\n",
      "Epoch 39/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.0309 - accuracy: 0.9909 - val_loss: 0.0609 - val_accuracy: 0.9833\n",
      "Epoch 40/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.0307 - accuracy: 0.9911 - val_loss: 0.0627 - val_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f739c1b9518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='log'),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZdROjFMSzqB",
    "outputId": "c9998eb3-fb24-4c00-c67a-f8b44532d3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned test accuracy: 0.9910333\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   X_train, y_train, verbose=0)\n",
    "\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AAslc8BbUWrt"
   },
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "tf.keras.models.save_model(model_for_export, '2_mnist_model_pruning.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU74G4M6Uheo"
   },
   "source": [
    "### Q-aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMue-1quUduS",
    "outputId": "b71b08aa-3abc-41a7-eb30-2fe3c7947cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1db550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1db550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitConvQuantizeConfig object at 0x7f746a22a320>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitConvQuantizeConfig object at 0x7f746a22a320>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e74a8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e74a8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e76d8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e76d8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e7908>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f746a1e7908>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,445\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 35\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HdBr8QpUn0b",
    "outputId": "2b84c98a-559c-42cb-af69-d66e4deb1f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "900/900 [==============================] - 1s 952us/sample - loss: 0.0571 - accuracy: 0.9844 - val_loss: 0.0763 - val_accuracy: 0.9800\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 0s 532us/sample - loss: 0.0213 - accuracy: 0.9911 - val_loss: 0.1015 - val_accuracy: 0.9600\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 0s 500us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9700\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 0s 490us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9700\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 0s 503us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9700\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 0s 508us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9700\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 0s 488us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9700\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 0s 555us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9700\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 0s 485us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9700\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 0s 515us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9700\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 0s 523us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9700\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 0s 496us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9700\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 0s 522us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9700\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 0s 515us/sample - loss: 9.3632e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9700\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 0s 519us/sample - loss: 8.4101e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9700\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 0s 518us/sample - loss: 7.7198e-04 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9700\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 0s 497us/sample - loss: 6.8296e-04 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9700\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 0s 489us/sample - loss: 6.3355e-04 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9700\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 0s 495us/sample - loss: 5.7773e-04 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9700\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 0s 493us/sample - loss: 5.5075e-04 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9700\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 0s 517us/sample - loss: 5.0141e-04 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9700\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 0s 504us/sample - loss: 4.7302e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9700\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 0s 498us/sample - loss: 4.4591e-04 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9700\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 0s 511us/sample - loss: 4.1791e-04 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9700\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 0s 517us/sample - loss: 3.9846e-04 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9700\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 0s 503us/sample - loss: 3.7088e-04 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9700\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 0s 503us/sample - loss: 3.5486e-04 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9700\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 0s 505us/sample - loss: 3.3320e-04 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9700\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 0s 516us/sample - loss: 3.0786e-04 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9700\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 0s 498us/sample - loss: 2.9162e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9700\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 0s 526us/sample - loss: 2.6797e-04 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9700\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 0s 498us/sample - loss: 2.5786e-04 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9700\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 0s 497us/sample - loss: 2.4016e-04 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9700\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 0s 528us/sample - loss: 2.2786e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9700\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 0s 514us/sample - loss: 2.1783e-04 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9700\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 0s 507us/sample - loss: 2.0609e-04 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9700\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 0s 479us/sample - loss: 1.9942e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9700\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 0s 497us/sample - loss: 1.7894e-04 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9700\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 0s 498us/sample - loss: 1.7281e-04 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 0.9700\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 0s 488us/sample - loss: 1.6232e-04 - accuracy: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9700\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 0s 488us/sample - loss: 1.5325e-04 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9700\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 0s 501us/sample - loss: 1.4446e-04 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9700\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 0s 497us/sample - loss: 1.3503e-04 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9700\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 0s 495us/sample - loss: 1.3039e-04 - accuracy: 1.0000 - val_loss: 0.1627 - val_accuracy: 0.9700\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 0s 490us/sample - loss: 1.2339e-04 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9700\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 0s 490us/sample - loss: 1.1962e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9800\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 0s 485us/sample - loss: 1.1079e-04 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9800\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 0s 500us/sample - loss: 1.0453e-04 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 0s 509us/sample - loss: 1.0061e-04 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9800\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 0s 506us/sample - loss: 9.5449e-05 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f746a0c7908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model against baseline\n",
    "\n",
    "train_images_subset = X_train[0:1000] # out of 60000\n",
    "train_labels_subset = y_train[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                  batch_size=10, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i5mfpIfUttE",
    "outputId": "4bffb5e3-6446-4b49-ccc0-c28a7537410b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = q_aware_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xRx896DaUzSZ"
   },
   "outputs": [],
   "source": [
    "q_aware_model.save('3_mnist_model_qaware.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMDgXKixV24s"
   },
   "source": [
    "### Convert Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OIW3P66SU5Wh"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "mNpVzGNkV-hT",
    "outputId": "9e031af3-fa1d-45db-8728-9b3de368187b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/4_mnist_model.tflite'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./1_mnist_model.h5','4_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "nP0nqyQnWQmY",
    "outputId": "e98d2c0c-1bc1-44bc-c242-6d07683b198f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/5_mnist_pruning_model.tflite'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_mnist_model_pruning.h5','5_mnist_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI5dR2_BWW0K",
    "outputId": "6e54b8a0-0f64-43f1-db9d-2f029600e846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quvantaised aware TFLite model to: 6_mnist_model_qaware.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "quantized_aware_tflite_file = '6_mnist_model_qaware.tflite'\n",
    "\n",
    "with open(quantized_aware_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "\n",
    "print('Saved quvantaised aware TFLite model to:', quantized_aware_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QduOdpLHXB7M"
   },
   "source": [
    "### Integer with Float fallback quantaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HCaunXAmW0Sa"
   },
   "outputs": [],
   "source": [
    "def Quant_int_with_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_quant_file = tflite_models_dir/filename\n",
    "    tflite_model_quant_file.write_bytes(tflite_model_quant)\n",
    "\n",
    "    return f'Converted - path {tflite_model_quant_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "AgYJEJIcXIA4",
    "outputId": "1ddfb469-2656-47d3-a789-a7b63f274b6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/7_mnist_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./1_mnist_model.h5', '7_mnist_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "3yLopRzNXLsO",
    "outputId": "ee98dd7b-0c1d-4114-dc97-5e163f01c132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/8_mnist_pruning_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./2_mnist_model_pruning.h5','8_mnist_pruning_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BubY_Gfvi9r7",
    "outputId": "cc6502ff-b5b0-4ba2-da7a-15ff360dbdf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24064"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "quantized_tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_quant_file = tflite_models_dir/\"9_mnist_Qaware_Integer_float_model.tflite\"\n",
    "tflite_model_quant_file.write_bytes(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-dl7BDpX2q8"
   },
   "source": [
    "### Float 16 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "F1rd9zwoXyI5"
   },
   "outputs": [],
   "source": [
    "def Quant_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "    tflite_fp16_model = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_fp16_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_fp16_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_fp16_file = tflite_models_fp16_dir/filename\n",
    "    tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_fp16_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "bKwgApR-X8uz",
    "outputId": "3e1f8c04-6f63-41d5-bdc8-6e0f79195a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/10_mnist_float16_model.tflite'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./1_mnist_model.h5', '10_mnist_float16_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "xbwNw7r6X-5U",
    "outputId": "8847cfc7-2b96-4a22-8d8e-1b156edd249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/11_mnist_float_pruning_model.tflite'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./2_mnist_model_pruning.h5', '11_mnist_float_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "ID7LoDiqYDz3",
    "outputId": "046a9591-be61-4f43-f06f-2487db6e791f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SavedModel file does not exist at: ./mnist_model_sperable.h5/{saved_model.pbtxt|saved_model.pb}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./mnist_model_sperable.h5','mnist_sperable_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGCANtJKmloH",
    "outputId": "b4ee3cd9-4bb8-4e86-a1ba-c0de997b734e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43568"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = tflite_models_dir/\"12_mnist_Qaware_float16_model.tflite\"\n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH-KGhE4YTLk"
   },
   "source": [
    "### Integer Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "MWQ9VPHuYVQD"
   },
   "outputs": [],
   "source": [
    "def Quant_integer(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "    def representative_data_gen():\n",
    "      for input_value in mnist_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "    tflite_int_quant_model = converter.convert()\n",
    "\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "    tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_integeronly_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "hu2k7mh8YZMg",
    "outputId": "0af8d068-fa20-4ce8-9276-633f67447eda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/13_fashion_mnist_integeronly_model.tflite'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./1_mnist_model.h5', '13_mnist_integeronly_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "KHd4CHwvYcZM",
    "outputId": "cc381e12-de8f-47f4-b80f-c0110e966154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/14_mnist_Integeronly_pruning_model.tflite'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./2_mnist_model_pruning.h5', '14_mnist_Integeronly_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown layer: QuantizeWrapper'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('3_mnist_model_qaware.h5','15_mnist_qaware_integer_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "gRp_DxPEZFnQ",
    "outputId": "f09cf12b-0ff6-4d2a-88df-e868f7276d95"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Quantization not yet supported for op: FAKE_QUANT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f4bf752305f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_output_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m  \u001b[0;31m# or tf.uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtflite_int_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.tflite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    467\u001b[0m       result = self._calibrate_quantize_model(\n\u001b[1;32m    468\u001b[0m           \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLOAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLOAT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           self.experimental_new_quantizer)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[0;34m(self, result, inference_input_type, inference_output_type, enable_mlir_quantizer)\u001b[0m\n\u001b[1;32m    241\u001b[0m     return calibrate_quantize.calibrate_and_quantize(\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_input_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         inference_output_type, allow_float, enable_mlir_quantizer)\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_base_converter_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36mcalibrate_and_quantize\u001b[0;34m(self, dataset_gen, input_type, output_type, allow_float, enable_mlir_quantizer)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         enable_mlir_quantizer)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   def calibrate_and_quantize_single(self, dataset_gen, input_type, output_type,\n",
      "\u001b[0;32m~/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\u001b[0m in \u001b[0;36mQuantizeModel\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mQuantizeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_lite_wrap_calibration_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrationWrapper_QuantizeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mCalibrationWrapper_swigregister\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensorflow_lite_wrap_calibration_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrationWrapper_swigregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mCalibrationWrapper_swigregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCalibrationWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Quantization not yet supported for op: FAKE_QUANT"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "tflite_int_quant_model = converter.convert()\n",
    "\n",
    "filename = filename+'.tflite'\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLfnYBi_Y_UE"
   },
   "source": [
    "### Evalvate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FlVsfYmfapme"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaROCUPyH0VN"
   },
   "source": [
    "### Keras model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3HelUev2D_rQ"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_single_unit(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  data = X_test[0]\n",
    "  data = data.reshape((1, 28, 28))\n",
    "  data_y = y_test[0:1]\n",
    "  score = model.evaluate(data, data_y, verbose=0)\n",
    "\n",
    "  result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UphrjYx4GShd",
    "outputId": "c45fc599-d5a5-4712-dc28-a0199570b9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 0.34443020820617676, 'Score': 1.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4wu0T0JHABA",
    "outputId": "de6d1cdb-e2c7-4842-a2b7-72516a24f3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 0.18784451484680176, 'Score': 1.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./2_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cIMCeFsfHUIw"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_test_set(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  score = score = model.evaluate(X_test, y_test, verbose =0)\n",
    "\n",
    "  result = {'Time to infer for the whole test set': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rSz-PSTHiev",
    "outputId": "9c385dd4-4071-454b-d041-80822830571f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to infer for the whole test set': 1.2550950050354004, 'Score': 0.9804}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./1_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwFkmrd-HmpA",
    "outputId": "ac6e65a4-42d8-4e7d-9639-c9571179f5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Time to infer for the whole test set': 1.0744516849517822, 'Score': 0.9784}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./2_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E973b0qH91Z"
   },
   "source": [
    "### TF Lite Model Evaluvation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ze6PZOG8amGr"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_test_set(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in X_test:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == y_test[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  results = {'time': (time.time() - start_time),\n",
    "             'accuracy': accuracy}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-U4VKkOUSBi"
   },
   "source": [
    "### TF Lite Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkrgvhyOJQTa",
    "outputId": "e882fb6d-c05b-47ac-fcb3-bfe4fbd075ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.035888671875, 'accuracy': 0.9804}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/4_mnist_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GuvDc23JSbl",
    "outputId": "ec2b42e9-c0f5-4398-eefc-93f8ca7afb12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0091731548309326, 'accuracy': 0.9784}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/5_mnist_pruning_model.tflite'\n",
    "interpreter_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CzVEe8J0kzP2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.4142177104949951, 'accuracy': 0.9711}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qaware Model\n",
    "tflite_model_file = 'tflite_models/6_mnist_model_qaware.tflite'\n",
    "interpreter_qaware = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqqScJyCUYeN"
   },
   "source": [
    "### Integer Float TF Lite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaALN_B-UREA",
    "outputId": "d39a99c4-4dd6-4fcd-88ed-d2e93930192e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0922648906707764, 'accuracy': 0.9803}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/7_mnist_Integer_float_model.tflite'\n",
    "interpreter_int_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNoTU5hKUev5",
    "outputId": "89c23c6c-d105-4cf5-b632-0e140fa717bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0958216190338135, 'accuracy': 0.9785}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/8_mnist_pruning_Integer_float_model.tflite'\n",
    "interpreter_int_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 2.127317190170288, 'accuracy': 0.971}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-aware TF Lite \n",
    "tflite_qaware_model_file = 'tflite_models/9_mnist_Qaware_Integer_float_model.tflite'\n",
    "interpreter_tflite_qaware_intfloat = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware_intfloat.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware_intfloat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-WBEicYlRYC"
   },
   "source": [
    "### Float Tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB1ptyTEXMY_",
    "outputId": "848b0d91-5d96-4d6e-f9cf-31def9da60c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0245018005371094, 'accuracy': 0.9804}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/10_mnist_float16_model.tflite'\n",
    "interpreter_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9U5CaiiXOLx",
    "outputId": "91d48c55-7596-40ee-aa3e-c48e082cc8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0211999416351318, 'accuracy': 0.9784}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/11_mnist_float_pruning_model.tflite'\n",
    "interpreter_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.4793415069580078, 'accuracy': 0.9711}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_qaware_model_file = 'tflite_models/12_mnist_Qaware_float16_model.tflite'\n",
    "interpreter_tflite_qaware_float16 = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware_float16.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware_float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okkuq4qBlUtg"
   },
   "source": [
    "### Integer Only TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KSSOaD5xYusE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.6056203842163086, 'accuracy': 0.9805}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/13_mnist_integeronly_model.tflite'\n",
    "interpreter_int = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nhfqVJESYvXV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.6063134670257568, 'accuracy': 0.9785}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/14_mnist_Integeronly_pruning_model.tflite'\n",
    "interpreter_int_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw6jufPWUi4-"
   },
   "source": [
    "### Single unit Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ISNOWEKoMk_T"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_single_unit(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  test_image = np.expand_dims(X_test[0], axis=0).astype(np.float32)\n",
    "  interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "  # Run inference.\n",
    "  interpreter.invoke()\n",
    "\n",
    "  # Post-processing: remove batch dimension and find the digit with highest\n",
    "  # probability.\n",
    "  output = interpreter.tensor(output_index)\n",
    "\n",
    "  results = {'time': (time.time() - start_time)}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CtdfccSNNjTJ",
    "outputId": "c4785d45-2031-4626-af3c-e4e8e515e3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003230571746826172}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "evaluate_tflite_model_single_unit(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xaD5wuZ-NpS7",
    "outputId": "afbc484d-5d9b-4c19-f2e8-46730bdb24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0006458759307861328}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RCfwkechNx6D",
    "outputId": "95c1bcbe-acf7-41bf-8593-542e41c9206b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003819465637207031}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hE2TT1Asl-T_",
    "outputId": "ffb77f4e-6f83-4b3b-937e-49b65b99007c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.00030803680419921875}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "W9B3FA1TV3yK",
    "outputId": "ce64a1e6-6ea2-448d-c1bc-10a97a92171e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0002536773681640625}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kmyMu1L-X_rJ",
    "outputId": "7dafaf58-7f2e-422f-a78b-ae1e6933fcc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0006232261657714844}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dTm4xyvVYFRs",
    "outputId": "f3637e39-0eab-42a4-c031-cd3be04596f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003516674041748047}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kLjCD9luZyZh",
    "outputId": "9406986d-14af-49d0-f8ba-d17553b17985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0005064010620117188}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.00037598609924316406}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0005180835723876953}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_tflite_qaware_intfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HpG8cjckZ2oS",
    "outputId": "690c6081-f0f8-4ad2-adf0-4ee58dcc6c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003058910369873047}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_tflite_qaware_float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ezWjyFaJRSZj",
    "6yN3fanmRk8j",
    "jVr9KwBiSSNz",
    "hU74G4M6Uheo",
    "IMDgXKixV24s",
    "QduOdpLHXB7M",
    "P-dl7BDpX2q8",
    "oH-KGhE4YTLk",
    "rLfnYBi_Y_UE",
    "EGG619d3N5Am"
   ],
   "name": "CNN_2_Mnist_V1",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
