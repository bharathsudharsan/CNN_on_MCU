{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4zYZ-j7PRnU"
   },
   "source": [
    "### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TQN9b45WPH4a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAzeh1CBPcBL"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvAMKMkOPZv9",
    "outputId": "0028e9c8-e684-4b4e-cbd8-3550d3a79803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Image shape: (60000, 28, 28) Test Image shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Train Image shape:\", X_train.shape, \"Test Image shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tFb6jWAkPfdD"
   },
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBUVyLcAPjwi"
   },
   "source": [
    "### Conv2D Model - Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2A-wIeHPgPK",
    "outputId": "22d6efdb-9642-4765-a457-9cbefc98073c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGUrrQKVQKIU"
   },
   "source": [
    "### Train Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2_d3N_5_PuKE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "wR0ljGKmQJA6",
    "outputId": "5e952403-432f-4499-bcd5-f99672752c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 186us/sample - loss: 0.5331 - accuracy: 0.8193 - val_loss: 0.4106 - val_accuracy: 0.8553\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.3722 - accuracy: 0.8705 - val_loss: 0.3644 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.3396 - accuracy: 0.8812 - val_loss: 0.3480 - val_accuracy: 0.8788\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.3184 - accuracy: 0.8890 - val_loss: 0.3380 - val_accuracy: 0.8811\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 172us/sample - loss: 0.3043 - accuracy: 0.8927 - val_loss: 0.3364 - val_accuracy: 0.8825\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.2942 - accuracy: 0.8974 - val_loss: 0.3255 - val_accuracy: 0.8836\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.2844 - accuracy: 0.9007 - val_loss: 0.3147 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.2770 - accuracy: 0.9036 - val_loss: 0.3161 - val_accuracy: 0.8869\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 0.2702 - accuracy: 0.9046 - val_loss: 0.3111 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 0.2645 - accuracy: 0.9068 - val_loss: 0.3065 - val_accuracy: 0.8919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f402ea1b7f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wVJXIMgUQRuT"
   },
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save('1_fashion_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "fN577u1YQSRT",
    "outputId": "4654ba64-478c-4c86-e47d-d1f86881faea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.8919\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVr9KwBiSSNz"
   },
   "source": [
    "### Train model with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jme0bFPQSWUZ",
    "outputId": "4f284b82-a48e-467b-8e73-2d7d97ae0b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/home/db/.virtualenvs/LR/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "AYgEbllrSYWh",
    "outputId": "488a791b-64e1-4b31-fa70-e8a2d068f818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/db/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:219: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X_train.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wWOEo7EiSmbx",
    "outputId": "e4b4e0b2-332e-4607-b121-f77330967a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/40\n",
      "54000/54000 [==============================] - 9s 175us/sample - loss: 0.2681 - accuracy: 0.9060 - val_loss: 0.2598 - val_accuracy: 0.9063\n",
      "Epoch 2/40\n",
      "54000/54000 [==============================] - 8s 153us/sample - loss: 0.2599 - accuracy: 0.9085 - val_loss: 0.2613 - val_accuracy: 0.9075\n",
      "Epoch 3/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2557 - accuracy: 0.9102 - val_loss: 0.2636 - val_accuracy: 0.9063\n",
      "Epoch 4/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2536 - accuracy: 0.9116 - val_loss: 0.2669 - val_accuracy: 0.9035\n",
      "Epoch 5/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.2548 - accuracy: 0.9109 - val_loss: 0.2737 - val_accuracy: 0.9015\n",
      "Epoch 6/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2534 - accuracy: 0.9115 - val_loss: 0.2706 - val_accuracy: 0.9042\n",
      "Epoch 7/40\n",
      "54000/54000 [==============================] - 8s 154us/sample - loss: 0.2501 - accuracy: 0.9121 - val_loss: 0.2694 - val_accuracy: 0.9028\n",
      "Epoch 8/40\n",
      "54000/54000 [==============================] - 8s 154us/sample - loss: 0.2482 - accuracy: 0.9130 - val_loss: 0.2734 - val_accuracy: 0.9000\n",
      "Epoch 9/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2484 - accuracy: 0.9135 - val_loss: 0.2723 - val_accuracy: 0.9027\n",
      "Epoch 10/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2513 - accuracy: 0.9118 - val_loss: 0.2838 - val_accuracy: 0.8993\n",
      "Epoch 11/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2512 - accuracy: 0.9116 - val_loss: 0.2819 - val_accuracy: 0.8982\n",
      "Epoch 12/40\n",
      "54000/54000 [==============================] - 9s 170us/sample - loss: 0.2478 - accuracy: 0.9133 - val_loss: 0.2779 - val_accuracy: 0.9002\n",
      "Epoch 13/40\n",
      "54000/54000 [==============================] - 9s 166us/sample - loss: 0.2468 - accuracy: 0.9138 - val_loss: 0.2782 - val_accuracy: 0.9008\n",
      "Epoch 14/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.2503 - accuracy: 0.9122 - val_loss: 0.2848 - val_accuracy: 0.8990\n",
      "Epoch 15/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2629 - accuracy: 0.9059 - val_loss: 0.2915 - val_accuracy: 0.8975\n",
      "Epoch 16/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.2587 - accuracy: 0.9077 - val_loss: 0.2921 - val_accuracy: 0.8958\n",
      "Epoch 17/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2523 - accuracy: 0.9103 - val_loss: 0.2882 - val_accuracy: 0.8953\n",
      "Epoch 18/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2506 - accuracy: 0.9113 - val_loss: 0.2910 - val_accuracy: 0.8975\n",
      "Epoch 19/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.2571 - accuracy: 0.9088 - val_loss: 0.3028 - val_accuracy: 0.8933\n",
      "Epoch 20/40\n",
      "54000/54000 [==============================] - 8s 154us/sample - loss: 0.2607 - accuracy: 0.9082 - val_loss: 0.2932 - val_accuracy: 0.8938\n",
      "Epoch 21/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2585 - accuracy: 0.9076 - val_loss: 0.2971 - val_accuracy: 0.8962\n",
      "Epoch 22/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2550 - accuracy: 0.9095 - val_loss: 0.2939 - val_accuracy: 0.8990\n",
      "Epoch 23/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2584 - accuracy: 0.9088 - val_loss: 0.2969 - val_accuracy: 0.8950\n",
      "Epoch 24/40\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.2557 - accuracy: 0.9097 - val_loss: 0.2965 - val_accuracy: 0.8952\n",
      "Epoch 25/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2538 - accuracy: 0.9101 - val_loss: 0.2965 - val_accuracy: 0.8940\n",
      "Epoch 26/40\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.2515 - accuracy: 0.9102 - val_loss: 0.2938 - val_accuracy: 0.8967\n",
      "Epoch 27/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2501 - accuracy: 0.9107 - val_loss: 0.2926 - val_accuracy: 0.8955\n",
      "Epoch 28/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2499 - accuracy: 0.9110 - val_loss: 0.3079 - val_accuracy: 0.8905\n",
      "Epoch 29/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2603 - accuracy: 0.9059 - val_loss: 0.3019 - val_accuracy: 0.8937\n",
      "Epoch 30/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2566 - accuracy: 0.9075 - val_loss: 0.2987 - val_accuracy: 0.8935\n",
      "Epoch 31/40\n",
      "54000/54000 [==============================] - 9s 157us/sample - loss: 0.2547 - accuracy: 0.9086 - val_loss: 0.2975 - val_accuracy: 0.8937\n",
      "Epoch 32/40\n",
      "54000/54000 [==============================] - 9s 160us/sample - loss: 0.2529 - accuracy: 0.9091 - val_loss: 0.2981 - val_accuracy: 0.8942\n",
      "Epoch 33/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2517 - accuracy: 0.9094 - val_loss: 0.3004 - val_accuracy: 0.8935\n",
      "Epoch 34/40\n",
      "54000/54000 [==============================] - 8s 157us/sample - loss: 0.2505 - accuracy: 0.9102 - val_loss: 0.2979 - val_accuracy: 0.8953\n",
      "Epoch 35/40\n",
      "54000/54000 [==============================] - 9s 159us/sample - loss: 0.2494 - accuracy: 0.9103 - val_loss: 0.2986 - val_accuracy: 0.8940\n",
      "Epoch 36/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2482 - accuracy: 0.9111 - val_loss: 0.2981 - val_accuracy: 0.8950\n",
      "Epoch 37/40\n",
      "54000/54000 [==============================] - 9s 158us/sample - loss: 0.2473 - accuracy: 0.9110 - val_loss: 0.2962 - val_accuracy: 0.8960\n",
      "Epoch 38/40\n",
      "54000/54000 [==============================] - 10s 180us/sample - loss: 0.2466 - accuracy: 0.9114 - val_loss: 0.2988 - val_accuracy: 0.8950\n",
      "Epoch 39/40\n",
      "54000/54000 [==============================] - 9s 161us/sample - loss: 0.2459 - accuracy: 0.9117 - val_loss: 0.2984 - val_accuracy: 0.8945\n",
      "Epoch 40/40\n",
      "54000/54000 [==============================] - 9s 168us/sample - loss: 0.2452 - accuracy: 0.9121 - val_loss: 0.2961 - val_accuracy: 0.8962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ffc0308d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir='log'),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(X_train, y_train,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2ZdROjFMSzqB",
    "outputId": "1a98f066-88bc-4d12-d180-fb6f8680ad20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned test accuracy: 0.9112833\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   X_train, y_train, verbose=0)\n",
    "\n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AAslc8BbUWrt"
   },
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "tf.keras.models.save_model(model_for_export, '2_fashion_mnist_model_pruning.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU74G4M6Uheo"
   },
   "source": [
    "### Q-aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMue-1quUduS",
    "outputId": "5b061f60-1817-47ad-fa52-9f75b183f8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc282ac8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc282ac8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitConvQuantizeConfig object at 0x7f40ad1c5470>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitConvQuantizeConfig object at 0x7f40ad1c5470>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc278828>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc278828>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc2786d8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc2786d8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc2780f0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "WARNING: AutoGraph could not transform <bound method Default8BitQuantizeConfig.set_quantize_activations of <tensorflow_model_optimization.python.core.quantization.keras.default_8bit.default_8bit_quantize_registry.Default8BitQuantizeConfig object at 0x7f3fdc2780f0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected an indented block (<unknown>, line 14)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                20295     \n",
      "=================================================================\n",
      "Total params: 20,445\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 35\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HdBr8QpUn0b",
    "outputId": "f5514f56-d1fe-4c24-d875-b52da436f9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.3110 - accuracy: 0.5867 - val_loss: 0.8051 - val_accuracy: 0.6700\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.7722 - val_loss: 0.6791 - val_accuracy: 0.7600\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.8033 - val_loss: 0.6681 - val_accuracy: 0.7400\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8400 - val_loss: 0.5631 - val_accuracy: 0.7900\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8456 - val_loss: 0.6358 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.8578 - val_loss: 0.6034 - val_accuracy: 0.7800\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8822 - val_loss: 0.5369 - val_accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8889 - val_loss: 0.5262 - val_accuracy: 0.8100\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.9133 - val_loss: 0.5485 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.9111 - val_loss: 0.4965 - val_accuracy: 0.8400\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9267 - val_loss: 0.5116 - val_accuracy: 0.8200\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9289 - val_loss: 0.5379 - val_accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9267 - val_loss: 0.5141 - val_accuracy: 0.8200\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9378 - val_loss: 0.5269 - val_accuracy: 0.7900\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9411 - val_loss: 0.5586 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9422 - val_loss: 0.5617 - val_accuracy: 0.8100\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9489 - val_loss: 0.5810 - val_accuracy: 0.8100\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9489 - val_loss: 0.5802 - val_accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9644 - val_loss: 0.5794 - val_accuracy: 0.8300\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9667 - val_loss: 0.5952 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9667 - val_loss: 0.5699 - val_accuracy: 0.8200\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9667 - val_loss: 0.6142 - val_accuracy: 0.8000\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.9744 - val_loss: 0.5981 - val_accuracy: 0.8200\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9756 - val_loss: 0.6673 - val_accuracy: 0.8000\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9789 - val_loss: 0.6499 - val_accuracy: 0.8100\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0827 - accuracy: 0.9778 - val_loss: 0.7025 - val_accuracy: 0.8000\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9767 - val_loss: 0.6346 - val_accuracy: 0.8200\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9800 - val_loss: 0.7226 - val_accuracy: 0.7900\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9789 - val_loss: 0.6783 - val_accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9756 - val_loss: 0.6680 - val_accuracy: 0.8300\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9878 - val_loss: 0.7272 - val_accuracy: 0.8100\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9856 - val_loss: 0.6916 - val_accuracy: 0.8100\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9889 - val_loss: 0.7132 - val_accuracy: 0.8200\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9911 - val_loss: 0.7200 - val_accuracy: 0.8400\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9922 - val_loss: 0.7340 - val_accuracy: 0.8100\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9922 - val_loss: 0.7299 - val_accuracy: 0.8100\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9900 - val_loss: 0.7688 - val_accuracy: 0.8200\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9989 - val_loss: 0.7462 - val_accuracy: 0.8300\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9956 - val_loss: 0.7641 - val_accuracy: 0.8100\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9967 - val_loss: 0.7979 - val_accuracy: 0.7900\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9878 - val_loss: 0.7862 - val_accuracy: 0.8100\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9967 - val_loss: 0.7922 - val_accuracy: 0.8200\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 0.9989 - val_loss: 0.8172 - val_accuracy: 0.8200\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9989 - val_loss: 0.8100 - val_accuracy: 0.8400\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 0.8561 - val_accuracy: 0.8100\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9989 - val_loss: 0.8519 - val_accuracy: 0.8100\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9978 - val_loss: 0.8824 - val_accuracy: 0.8000\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.8200\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9989 - val_loss: 0.9128 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa545dcb70>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the model against baseline\n",
    "\n",
    "train_images_subset = X_train[0:1000] # out of 60000\n",
    "train_labels_subset = y_train[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images_subset, train_labels_subset,\n",
    "                  batch_size=10, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i5mfpIfUttE",
    "outputId": "a2661852-37e3-4da8-d735-a39a298747b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to full set infer': 1.193819522857666, 'Score': 0.8833}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "import time\n",
    "start_time_infer = time.time()\n",
    "score = q_aware_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "result = {'Time to full set infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkZi8QN7M308",
    "outputId": "e1f9f189-0afb-4727-cb4e-65804c4fac01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Time to single unit infer': 0.030364990234375, 'Score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "start_time_infer = time.time()\n",
    "#model = tf.keras.models.load_model('fashion_mnist_model_qaware.h5', compile = True)\n",
    "data = X_test[0]\n",
    "data = data.reshape((1, 28, 28))\n",
    "data_y = y_test[0:1]\n",
    "score = q_aware_model.evaluate(data, data_y, verbose=0)\n",
    "\n",
    "result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xRx896DaUzSZ"
   },
   "outputs": [],
   "source": [
    "q_aware_model.save('3_fashion_mnist_model_qaware.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMDgXKixV24s"
   },
   "source": [
    "### Convert Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OIW3P66SU5Wh"
   },
   "outputs": [],
   "source": [
    "def ConvertTFLite(model_path, filename):\n",
    "  try:\n",
    "    # Loading Model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    #Specify path\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    filename = filename+\".tflite\"\n",
    "    tflite_model_file = tflite_models_dir/filename\n",
    "    # Save Model\n",
    "    tflite_model_file.write_bytes(tflite_model)\n",
    "\n",
    "    return f'Converted to TFLite, path {tflite_model_file}'\n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNpVzGNkV-hT",
    "outputId": "66c1d732-9b18-4bc4-d558-78091dc94761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/4_fashion_mnist_model.tflite'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./1_fashion_mnist_model.h5','4_fashion_mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP0nqyQnWQmY",
    "outputId": "f10a44f3-b670-4fa7-8225-c1b2caa96d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted to TFLite, path tflite_models/5_fashion_mnist_pruning_model.tflite'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertTFLite('./2_fashion_mnist_model_pruning.h5','5_fashion_mnist_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WI5dR2_BWW0K",
    "outputId": "1bc457c9-3fea-4f0c-af4d-3fa870ada86f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quvantaised aware TFLite model to: 6_fashion_mnist_model_qaware.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "quantized_aware_tflite_file = '6_fashion_mnist_model_qaware.tflite'\n",
    "\n",
    "with open(quantized_aware_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_tflite_model)\n",
    "\n",
    "print('Saved quvantaised aware TFLite model to:', quantized_aware_tflite_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QduOdpLHXB7M"
   },
   "source": [
    "### Integer with Float fallback quantaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HCaunXAmW0Sa"
   },
   "outputs": [],
   "source": [
    "def Quant_int_with_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model_quant = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_quant_file = tflite_models_dir/filename\n",
    "    tflite_model_quant_file.write_bytes(tflite_model_quant)\n",
    "\n",
    "    return f'Converted - path {tflite_model_quant_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AgYJEJIcXIA4",
    "outputId": "62601e51-66ac-41bc-8934-c308f1a2ea1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/7_fashion_mnist_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./1_fashion_mnist_model.h5', '7_fashion_mnist_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yLopRzNXLsO",
    "outputId": "663c3fb9-f507-4a32-9073-8f309fc5c29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/8_fashion_mnist_pruning_Integer_float_model.tflite'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_int_with_float('./2_fashion_mnist_model_pruning.h5','8_fashion_mnist_pruning_Integer_float_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BubY_Gfvi9r7",
    "outputId": "d161f061-0d41-42ff-9ffd-1230046b878f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24064"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "mnist_train, _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "quantized_tflite_model = converter.convert()\n",
    "tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_quant_file = tflite_models_dir/\"9_fashion_mnist_Qaware_Integer_float_model.tflite\"\n",
    "tflite_model_quant_file.write_bytes(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-dl7BDpX2q8"
   },
   "source": [
    "### Float 16 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "F1rd9zwoXyI5"
   },
   "outputs": [],
   "source": [
    "def Quant_float(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "    tflite_fp16_model = converter.convert()\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_fp16_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_fp16_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_fp16_file = tflite_models_fp16_dir/filename\n",
    "    tflite_model_fp16_file.write_bytes(tflite_fp16_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_fp16_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKwgApR-X8uz",
    "outputId": "3f7287fb-af80-4fbe-87b6-5fa01dc69f80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/10_fashion_mnist_float16_model.tflite'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./1_fashion_mnist_model.h5', '10_fashion_mnist_float16_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbwNw7r6X-5U",
    "outputId": "bac61140-85e4-4782-9ccc-b070357ebba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/11_fashion_mnist_float_pruning_model.tflite'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_float('./2_fashion_mnist_model_pruning.h5', '11_fashion_mnist_float_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGCANtJKmloH",
    "outputId": "f86c1307-b9b7-434a-8725-bdf5b35343a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43568"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_fp16_model = converter.convert()\n",
    "tflite_model_fp16_file = tflite_models_dir/\"12_fashion_mnist_Qaware_float16_model.tflite\"\n",
    "tflite_model_fp16_file.write_bytes(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oH-KGhE4YTLk"
   },
   "source": [
    "### Integer Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "MWQ9VPHuYVQD"
   },
   "outputs": [],
   "source": [
    "def Quant_integer(model_name, filename):\n",
    "  try:\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    mnist_train, _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "    def representative_data_gen():\n",
    "      for input_value in mnist_ds.take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "    converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "\n",
    "    tflite_int_quant_model = converter.convert()\n",
    "\n",
    "    filename = filename+'.tflite'\n",
    "    tflite_models_dir = pathlib.Path(\"tflite_models/\")\n",
    "    tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    tflite_model_integeronly_file = tflite_models_dir/filename\n",
    "    tflite_model_integeronly_file.write_bytes(tflite_int_quant_model)\n",
    "\n",
    "    return f'Converted - path {tflite_model_integeronly_file}'\n",
    "  \n",
    "  except Exception as e:\n",
    "    return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hu2k7mh8YZMg",
    "outputId": "00f1f0a8-6258-4392-c286-df4c48a1dc3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/13_fashion_mnist_integeronly_model.tflite'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./1_fashion_mnist_model.h5', '13_fashion_mnist_integeronly_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "KHd4CHwvYcZM",
    "outputId": "afde80f6-b8a3-4e77-da36-3726fde1366d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Converted - path tflite_models/14_fashion_mnist_Integeronly_pruning_model.tflite'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Quant_integer('./2_fashion_mnist_model_pruning.h5', '14_fashion_mnist_Integeronly_pruning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "siAr85uznKne"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown layer: QuantizeWrapper'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quant_integer('3_fashion_mnist_model_qaware.h5','15_fashion_mnist_qaware_integer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLfnYBi_Y_UE"
   },
   "source": [
    "### Evalvate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "FlVsfYmfapme"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaROCUPyH0VN"
   },
   "source": [
    "### Keras model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "3HelUev2D_rQ"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_single_unit(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  data = X_test[0]\n",
    "  data = data.reshape((1, 28, 28))\n",
    "  data_y = y_test[0:1]\n",
    "  score = model.evaluate(data, data_y, verbose=0)\n",
    "\n",
    "  result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UphrjYx4GShd",
    "outputId": "830b296a-9092-4101-b0d7-c0fdadf0d058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 0.3266921043395996, 'Score': 1.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./1_fashion_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "r4wu0T0JHABA",
    "outputId": "009ee0db-d8c9-4e4e-9133-bb4aa8377e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 0.19787001609802246, 'Score': 1.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_single_unit('./2_fashion_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "cIMCeFsfHUIw"
   },
   "outputs": [],
   "source": [
    "def evaluate_keras_model_test_set(model_path):\n",
    "  start_time_infer = time.time()\n",
    "  model = tf.keras.models.load_model(model_path, compile = True)\n",
    "  model.compile(optimizer='adam',\n",
    "           loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "           metrics=['accuracy'])\n",
    "  score = score = model.evaluate(X_test, y_test, verbose =0)\n",
    "\n",
    "  result = {'Time to single unit infer': (time.time() - start_time_infer),\n",
    "            'Score' : score[1]}\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "8rSz-PSTHiev",
    "outputId": "82af8e9d-ab80-4b9e-a7bb-1f0ba12eb18b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 1.2570888996124268, 'Score': 0.8919}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./1_fashion_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "IwFkmrd-HmpA",
    "outputId": "5fc0f565-5b19-4add-bc02-c2ec4b28e041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Time to single unit infer': 1.1714470386505127, 'Score': 0.8886}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_keras_model_test_set('./2_fashion_mnist_model_pruning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E973b0qH91Z"
   },
   "source": [
    "### TF Lite Model Evaluvation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ze6PZOG8amGr"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_test_set(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for test_image in X_test:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  accurate_count = 0\n",
    "  for index in range(len(prediction_digits)):\n",
    "    if prediction_digits[index] == y_test[index]:\n",
    "      accurate_count += 1\n",
    "  accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "  results = {'time': (time.time() - start_time),\n",
    "             'accuracy': accuracy}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-U4VKkOUSBi"
   },
   "source": [
    "### TF Lite Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "AkrgvhyOJQTa",
    "outputId": "9af66cc6-13ce-4bd8-8246-1b269dc887b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.054225206375122, 'accuracy': 0.8919}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/4_fashion_mnist_model.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0GuvDc23JSbl",
    "outputId": "818e9c64-3e35-4d17-cc65-83ff8036471d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0251374244689941, 'accuracy': 0.8886}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/5_fashion_mnist_pruning_model.tflite'\n",
    "interpreter_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CzVEe8J0kzP2",
    "outputId": "70269bb8-4ea4-4a60-bdc8-99552588ecd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.519986629486084, 'accuracy': 0.8832}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qaware Model\n",
    "tflite_model_file = '6_fashion_mnist_model_qaware.tflite'\n",
    "interpreter_qaware = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqqScJyCUYeN"
   },
   "source": [
    "### Integer Float TF Lite models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UaALN_B-UREA",
    "outputId": "8936033d-2ced-4ab7-bbba-28c9e909f144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.7407429218292236, 'accuracy': 0.8916}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/7_fashion_mnist_Integer_float_model.tflite'\n",
    "interpreter_int_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xNoTU5hKUev5",
    "outputId": "8c3bb8b0-02ff-40da-ac7d-0a647fdf5589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.7226157188415527, 'accuracy': 0.8881}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/8_fashion_mnist_pruning_Integer_float_model.tflite'\n",
    "interpreter_int_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "nfC78dX-OOl5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 2.270085573196411, 'accuracy': 0.8826}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q-aware TF Lite \n",
    "tflite_qaware_model_file = 'tflite_models/9_fashion_mnist_Qaware_Integer_float_model.tflite'\n",
    "interpreter_tflite_qaware = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-WBEicYlRYC"
   },
   "source": [
    "### Float Tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YB1ptyTEXMY_",
    "outputId": "6811c3ab-d643-42de-ef7f-ece292e368af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0752472877502441, 'accuracy': 0.8919}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/10_fashion_mnist_float16_model.tflite'\n",
    "interpreter_float = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_float.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Y9U5CaiiXOLx",
    "outputId": "a36b6fd1-c60c-433a-dc39-c27b08b60ac7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.0634164810180664, 'accuracy': 0.8887}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/11_fashion_mnist_float_pruning_model.tflite'\n",
    "interpreter_float_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_float_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "WYVGu1KlRQwG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.5382635593414307, 'accuracy': 0.8829}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_qaware_model_file = 'tflite_models/12_fashion_mnist_Qaware_float16_model.tflite'\n",
    "interpreter_tflite_qaware = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "interpreter_tflite_qaware.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_tflite_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Okkuq4qBlUtg"
   },
   "source": [
    "### Integer Only TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "KSSOaD5xYusE",
    "outputId": "3dbd0e21-eaf6-426e-d491-ceb537ce980c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.6675422191619873, 'accuracy': 0.8916}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "tflite_model_file = 'tflite_models/13_fashion_mnist_integeronly_model.tflite'\n",
    "interpreter_int = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter_int.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "nhfqVJESYvXV",
    "outputId": "482ddbd4-7ad5-407b-a803-9e470d8de9f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 1.7024378776550293, 'accuracy': 0.8881}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purning TF Lite \n",
    "tflite_pruning_model_file = 'tflite_models/14_fashion_mnist_Integeronly_pruning_model.tflite'\n",
    "interpreter_int_pruning = tf.lite.Interpreter(model_path=str(tflite_pruning_model_file))\n",
    "interpreter_int_pruning.allocate_tensors()\n",
    "evaluate_tflite_model_test_set(interpreter_int_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "5jOERuHxRVrc"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'tflite_models/15_fashion_mnist_Qaware_integer_model.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-6df59cd240df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtflite_qaware_model_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tflite_models/15_fashion_mnist_Qaware_integer_model.tflite'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minterpreter_tflite_qaware\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_qaware_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minterpreter_tflite_qaware\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluate_tflite_model_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter_tflite_qaware\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/LR/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates)\u001b[0m\n\u001b[1;32m    207\u001b[0m       self._interpreter = (\n\u001b[1;32m    208\u001b[0m           _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\n\u001b[0;32m--> 209\u001b[0;31m               model_path, self._custom_op_registerers))\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to open {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not open 'tflite_models/15_fashion_mnist_Qaware_integer_model.tflite'."
     ]
    }
   ],
   "source": [
    "# tflite_qaware_model_file = 'tflite_models/15_fashion_mnist_Qaware_integer_model.tflite'\n",
    "# interpreter_tflite_qaware = tf.lite.Interpreter(model_path=str(tflite_qaware_model_file))\n",
    "# interpreter_tflite_qaware.allocate_tensors()\n",
    "# evaluate_tflite_model_test_set(interpreter_tflite_qaware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw6jufPWUi4-"
   },
   "source": [
    "### Find unit inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ISNOWEKoMk_T"
   },
   "outputs": [],
   "source": [
    "# Evaluate the mode\n",
    "def evaluate_tflite_model_single_unit(interpreter):\n",
    "  start_time = time.time()\n",
    "\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  test_image = np.expand_dims(X_test[0], axis=0).astype(np.float32)\n",
    "  interpreter.set_tensor(input_index, test_image)\n",
    "  \n",
    "  # Run inference.\n",
    "  interpreter.invoke()\n",
    "\n",
    "  # Post-processing: remove batch dimension and find the digit with highest\n",
    "  # probability.\n",
    "  output = interpreter.tensor(output_index)\n",
    "\n",
    "  results = {'time': (time.time() - start_time)}\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "CtdfccSNNjTJ",
    "outputId": "c4785d45-2031-4626-af3c-e4e8e515e3d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0002574920654296875}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Lite\n",
    "evaluate_tflite_model_single_unit(interpreter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xaD5wuZ-NpS7",
    "outputId": "afbc484d-5d9b-4c19-f2e8-46730bdb24cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.00024962425231933594}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "RCfwkechNx6D",
    "outputId": "95c1bcbe-acf7-41bf-8593-542e41c9206b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003440380096435547}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hE2TT1Asl-T_",
    "outputId": "ffb77f4e-6f83-4b3b-937e-49b65b99007c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003364086151123047}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_qaware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "W9B3FA1TV3yK",
    "outputId": "ce64a1e6-6ea2-448d-c1bc-10a97a92171e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0003695487976074219}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kmyMu1L-X_rJ",
    "outputId": "7dafaf58-7f2e-422f-a78b-ae1e6933fcc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0002636909484863281}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dTm4xyvVYFRs",
    "outputId": "f3637e39-0eab-42a4-c031-cd3be04596f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.0002579689025878906}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "kLjCD9luZyZh",
    "outputId": "9406986d-14af-49d0-f8ba-d17553b17985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.00037932395935058594}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HpG8cjckZ2oS",
    "outputId": "690c6081-f0f8-4ad2-adf0-4ee58dcc6c6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 0.00026035308837890625}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tflite_model_single_unit(interpreter_float_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_1_FashionMnist_V6",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
